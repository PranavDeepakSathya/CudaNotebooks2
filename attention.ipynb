{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da5616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8969a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention: \n",
    "  def __init__ (self, batch_size:int, sequence_length:int, model_dimension, n_heads):\n",
    "    assert model_dimension % n_heads == 0 \n",
    "    self.B = batch_size\n",
    "    self.L = sequence_length\n",
    "    self.D = model_dimension\n",
    "    self.H = n_heads\n",
    "    self.dk = self.D // self.H \n",
    "    \n",
    "  def forward(self, X, W_Q, W_K, W_V): \n",
    "    # 1. Fuse weights (D, 3D)\n",
    "    W_Q_K_V = torch.cat([W_Q, W_K, W_V], dim=1)\n",
    "    \n",
    "    # 2. Project Input: (B, L, D) @ (D, 3D) -> (B, L, 3D)\n",
    "    projs = torch.matmul(X, W_Q_K_V)\n",
    "    \n",
    "    # 3. Reshape to isolate 3 (Q,K,V) and Heads\n",
    "    # Shape becomes: (B, L, 3, H, Dk)\n",
    "    T = projs.reshape(self.B, self.L, 3, self.H, self.dk)\n",
    "    \n",
    "    # 4. Permute to get Heads *before* Sequence Length\n",
    "    # We want: (3, B, H, L, Dk)\n",
    "    # 2 -> 0 (The QKV dimension moves to front)\n",
    "    # 0 -> 1 (Batch stays)\n",
    "    # 3 -> 2 (Heads move before Length)\n",
    "    # 1 -> 3 (Length moves after Heads)\n",
    "    # 4 -> 4 (Head Dim stays last)\n",
    "    T = T.permute(2, 0, 3, 1, 4)\n",
    "    \n",
    "    # 5. Split into Q, K, V\n",
    "    Q, K, V = T[0], T[1], T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e1229fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 \n",
    "sequence_length = 8 \n",
    "model_dimension = 256\n",
    "n_heads = 32\n",
    "\n",
    "X = torch.randn(batch_size, sequence_length, model_dimension)\n",
    "W_Q, W_K, W_V = torch.randn(model_dimension, model_dimension), torch.randn(model_dimension, model_dimension), torch.randn(model_dimension, model_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "578407e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = MultiHeadAttention(batch_size, sequence_length, model_dimension, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a0819fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m proj = \u001b[43mH\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW_Q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_K\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_V\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, X, W_Q, W_K, W_V)\u001b[39m\n\u001b[32m     14\u001b[39m projs = torch.matmul(X,  W_Q_K_V)\n\u001b[32m     15\u001b[39m T = projs.reshape(\u001b[38;5;28mself\u001b[39m.B, \u001b[38;5;28mself\u001b[39m.L, \u001b[32m3\u001b[39m, \u001b[38;5;28mself\u001b[39m.H, \u001b[38;5;28mself\u001b[39m.dk)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m Q = \u001b[43mT\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Q\n",
      "\u001b[31mRuntimeError\u001b[39m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 2"
     ]
    }
   ],
   "source": [
    "proj = H.forward(X,W_Q, W_K, W_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b34e1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mproj\u001b[49m.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'proj' is not defined"
     ]
    }
   ],
   "source": [
    "proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63923071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(32*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43852182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
