{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17af06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "from typing import List\n",
    "\n",
    "import cutlass\n",
    "import cutlass.cute as cute\n",
    "from cutlass.cute.runtime import from_dlpack\n",
    "from cutlass.cute import KeepPTX, KeepCUBIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc049d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.kernel\n",
    "def naive_elementwise_add_kernel(\n",
    "    gA: cute.Tensor,  # Input tensor A\n",
    "    gB: cute.Tensor,  # Input tensor B\n",
    "    gC: cute.Tensor,  # Output tensor C = A + B\n",
    "):\n",
    "  tidx, _, _ = cute.arch.thread_idx()\n",
    "  bidx, _, _ = cute.arch.block_idx()\n",
    "  bdim, _, _ = cute.arch.block_dim()\n",
    "  global_tid = (bidx*bdim) + tidx\n",
    "  m,n = gA.shape \n",
    "  X,Y = global_tid //n, (global_tid % n)\n",
    "  a_val = gA[X,Y]\n",
    "  b_val = gB[X,Y]\n",
    "  gC[X,Y] = a_val + b_val\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eafbce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.jit \n",
    "def naive_elementwise_add_launcher(mA: cute.Tensor, mB: cute.Tensor, mC: cute.Tensor):\n",
    "  n_tpb = 256 \n",
    "  m,n = mA.shape \n",
    "  kernel = naive_elementwise_add_kernel(mA, mB, mC)\n",
    "  kernel.launch(grid = ((m*n)//n_tpb,1,1), block = (n_tpb,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06faa7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M, N = 16384, 8192\n",
    "a = torch.randn(M, N, device=\"cuda\", dtype=torch.float16)  # Random input A\n",
    "b = torch.randn(M, N, device=\"cuda\", dtype=torch.float16)  # Random input B\n",
    "c = torch.zeros(M, N, device=\"cuda\", dtype=torch.float16)  # Output buffer\n",
    "\n",
    "# Calculate total elements for bandwidth calculations\n",
    "num_elements = sum([a.numel(), b.numel(), c.numel()])\n",
    "\n",
    "# Convert PyTorch tensors to CuTe tensors\n",
    "# -------------------------------------\n",
    "# from_dlpack creates CuTe tensor views of PyTorch tensors\n",
    "# assumed_align=16 ensures proper memory alignment for vectorized access (indeed we do need to ACTUALLY have our tensors aligned)\n",
    "a_ = from_dlpack(a, assumed_align=16)  # CuTe tensor A\n",
    "b_ = from_dlpack(b, assumed_align=16)  # CuTe tensor B\n",
    "c_ = from_dlpack(c, assumed_align=16)  # CuTe tensor C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80b0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_elementwise_add_compiled = cute.compile[KeepPTX](naive_elementwise_add_launcher, a_,b_,c_)\n",
    "naive_elementwise_add_compiled(a_, b_, c_)\n",
    "torch.testing.assert_close(c, a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6caa84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(callable, a_, b_, c_, num_elements):\n",
    "    avg_time_us = cute.testing.benchmark(\n",
    "        callable,\n",
    "        kernel_arguments=cute.testing.JitArguments(a_, b_, c_),\n",
    "        warmup_iterations=5,\n",
    "        iterations=100,\n",
    "    )\n",
    "\n",
    "    # Calculate metrics\n",
    "    # ----------------\n",
    "    dtype = a_.element_type\n",
    "\n",
    "    # Calculate total bytes transferred:\n",
    "    # - 2 reads (A and B) + 1 write (C)\n",
    "    # - Each element is dtype.width bits\n",
    "    bytes_per_element = dtype.width // 8\n",
    "    total_bytes = num_elements * bytes_per_element\n",
    "\n",
    "    # Calculate achieved bandwidth\n",
    "    achieved_bandwidth = total_bytes / (avg_time_us * 1000)  # GB/s\n",
    "\n",
    "    # Print results\n",
    "    # ------------\n",
    "    print(f\"Performance Metrics:\")\n",
    "    print(f\"-------------------\")\n",
    "    print(f\"Kernel execution time: {avg_time_us:.4f} us\")\n",
    "    print(f\"Memory throughput: {achieved_bandwidth:.2f} GB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f38aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "-------------------\n",
      "Kernel execution time: 507.6538 us\n",
      "Memory throughput: 1586.33 GB/s\n"
     ]
    }
   ],
   "source": [
    "benchmark(naive_elementwise_add_compiled, a_, b_,c_, num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c9d5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.kernel\n",
    "def vectorized_elementwise_kernel(gA:cute.Tensor, gB: cute.Tensor, gC: cute.Tensor): \n",
    "  #this time, the tensors are 4 vectorized and dtype is 32 bit for some reason we went from 16 to 32 bit. \n",
    "  #also our shapes are now zipped divided as ((1,4),(inner_m,inner_n)) which means that an access ((none), x,y) gives you \n",
    "  #the row 4vector chunk when viewing our tensor as tiled by 4 vector chunks.\n",
    "  tidx, _, _ = cute.arch.thread_idx()\n",
    "  bidx, _, _ = cute.arch.block_idx()\n",
    "  bdim, _, _ = cute.arch.block_dim()\n",
    "  global_tid = (bidx*bdim) + tidx\n",
    "  inner_m, inner_n = gA.shape[1] #the second mode of the shape tells us the (row vector tiled) shape. \n",
    "  inner_x, inner_y = (global_tid//inner_n), (global_tid % inner_n) #indeed we launch totally as many threads as there are elements \n",
    "  #where each element is now normalized to (1,4) vector unit atom.\n",
    "  a_val = gA[(None,(inner_x,inner_y))].load() #I guess we need the .load() to help us emit vector instruction \n",
    "  b_val = gB[(None,(inner_x,inner_y))].load()\n",
    "  gC[(None, (inner_x,inner_y))] = a_val + b_val \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b1ef8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DSL INFO] Tiled Tensors:\n",
      "[DSL INFO]   gA = tensor<ptr<f16, gmem, align<16>> o ((1,8),(16384,1024)):((0,1),(8192,8))>\n",
      "[DSL INFO]   gB = tensor<ptr<f16, gmem, align<16>> o ((1,8),(16384,1024)):((0,1),(8192,8))>\n",
      "[DSL INFO]   gC = tensor<ptr<f16, gmem, align<16>> o ((1,8),(16384,1024)):((0,1),(8192,8))>\n"
     ]
    }
   ],
   "source": [
    "@cute.jit\n",
    "def vectorized_elementwise_launcher(mA:cute.Tensor, mB:cute.Tensor, mC:cute.Tensor):\n",
    "  gA = cute.zipped_divide(mA, (1, 8))\n",
    "  gB = cute.zipped_divide(mB, (1, 8))\n",
    "  gC = cute.zipped_divide(mC, (1, 8))\n",
    "  print(\"[DSL INFO] Tiled Tensors:\")\n",
    "  print(f\"[DSL INFO]   gA = {gA}\")\n",
    "  print(f\"[DSL INFO]   gB = {gB}\")\n",
    "  print(f\"[DSL INFO]   gC = {gC}\")\n",
    "  n_tpb = 256\n",
    "  vectorized_elementwise_kernel(gA, gB, gC).launch(\n",
    "        grid=(cute.size(gC, mode=[1]) // n_tpb, 1, 1),\n",
    "        block=(n_tpb, 1, 1),\n",
    "    )\n",
    "  \n",
    "a = torch.randn(M, N, device=\"cuda\", dtype=torch.float16)\n",
    "b = torch.randn(M, N, device=\"cuda\", dtype=torch.float16)\n",
    "c = torch.zeros(M, N, device=\"cuda\", dtype=torch.float16)\n",
    "\n",
    "a_ = from_dlpack(a, assumed_align=16)\n",
    "b_ = from_dlpack(b, assumed_align=16)\n",
    "c_ = from_dlpack(c, assumed_align=16)\n",
    "\n",
    "vectorized_elementwise_compiled = cute.compile[KeepPTX](vectorized_elementwise_launcher, a_, b_, c_)\n",
    "vectorized_elementwise_compiled (a_, b_, c_)\n",
    "\n",
    "# verify correctness\n",
    "torch.testing.assert_close(c, a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13937f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "-------------------\n",
      "Kernel execution time: 511.9517 us\n",
      "Memory throughput: 1573.01 GB/s\n"
     ]
    }
   ],
   "source": [
    "benchmark(vectorized_elementwise_compiled, a_, b_, c_, num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc755a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
