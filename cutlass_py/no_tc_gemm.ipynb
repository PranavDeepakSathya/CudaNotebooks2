{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac1803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "from typing import List\n",
    "\n",
    "import cutlass\n",
    "import cutlass.cute as cute\n",
    "from cutlass.cute.runtime import from_dlpack\n",
    "from cutlass.cute import KeepPTX, KeepCUBIN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee0787cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.kernel#this is already gmem coalesced or idk tbh \n",
    "def naive_gemm(gA:cute.Tensor, gB:cute.Tensor, gC:cute.Tensor):\n",
    "  M,K = gA.shape\n",
    "  K,N = gB.shape\n",
    "  tid_x, tid_y, _ = cute.arch.thread_idx()\n",
    "  bid_x, bid_y, _ = cute.arch.block_idx()\n",
    "  bdim_x, bdim_y, _ = cute.arch.block_dim()\n",
    "  x = tid_x + (bid_x*bdim_x)\n",
    "  y = tid_y + (bid_y*bdim_y)\n",
    "  c_val = 0.0\n",
    "  if (x < N and y < M): \n",
    "    for k in range(K): \n",
    "      a_val = gA[y,k]\n",
    "      b_val = gB[k,x]\n",
    "      c_val += a_val*b_val\n",
    "    gC[y,x] = c_val\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a654e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.jit\n",
    "def naive_gemm_launcher(mA: cute.Tensor, mB: cute.Tensor, mC:cute.Tensor): \n",
    "  tpb_x = 32\n",
    "  tpb_y = 32 \n",
    "  M,K = mA.shape\n",
    "  K,N = mB.shape\n",
    "  kernel = naive_gemm(mA, mB, mC)\n",
    "  kernel.launch(grid = (N//tpb_x, M//tpb_y,1), block=(tpb_x, tpb_y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2afe255",
   "metadata": {},
   "outputs": [],
   "source": [
    "M,K,N = 4096, 4096, 4096 \n",
    "a = torch.randn(M,K, device = \"cuda\", dtype=torch.float32)\n",
    "b = torch.randn(K,N, device = \"cuda\", dtype=torch.float32)\n",
    "c = torch.zeros(M,N, device = \"cuda\", dtype = torch.float32)\n",
    "\n",
    "a_ = from_dlpack(a)\n",
    "b_ = from_dlpack(b)\n",
    "c_ = from_dlpack(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42651e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_gemm_compiled = cute.compile[KeepPTX](naive_gemm_launcher, a_, b_, c_)\n",
    "naive_gemm_compiled(a_,b_,c_)\n",
    "torch.testing.assert_close(c, torch.matmul(a, b), atol=1e-3, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d00fff00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -30.1699,  -86.6360,  -54.1250,  ...,  -26.8599,   68.7369,\n",
       "          -42.8419],\n",
       "        [  42.7018,   67.3336,  -37.8196,  ...,   90.4002,  103.0651,\n",
       "           67.8232],\n",
       "        [  21.6078,   69.5774,   58.3787,  ...,  -58.0930, -101.6149,\n",
       "           76.1043],\n",
       "        ...,\n",
       "        [  69.9713,    7.6569,   97.6248,  ...,   32.1981,   68.6552,\n",
       "          -36.1199],\n",
       "        [  80.1200,  -17.3889,  113.1297,  ...,  -38.8048,  -61.9338,\n",
       "         -101.6291],\n",
       "        [  82.0526,  -55.5913,   11.7599,  ...,  -22.2458,  -56.9337,\n",
       "          -51.5489]], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "000e1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(callable, a_, b_, c_, M,N,K):\n",
    "    avg_time_us = cute.testing.benchmark(\n",
    "        callable,\n",
    "        kernel_arguments=cute.testing.JitArguments(a_, b_, c_),\n",
    "        warmup_iterations=5,\n",
    "        iterations=100,\n",
    "    )\n",
    "    \n",
    "    flop = 2*M*N*K\n",
    "    \n",
    "    giga_flop_per_second = flop/(avg_time_us*1000)\n",
    "    print(giga_flop_per_second)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21da6473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7800.755069660659\n"
     ]
    }
   ],
   "source": [
    "benchmark(naive_gemm_compiled, a_,b_,c_, M,N,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3d00b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
