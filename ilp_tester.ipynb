{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a6b01bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"/tmp/tmpl_a417v3\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter\n",
    "\n",
    "from nvcc4jupyter import set_defaults\n",
    "set_defaults(compiler_args='-arch=sm_100a -Xptxas=-v -O0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e20b0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(84):\n",
    "#   print(f\"st.global.f32 [%thread_write_addr + {4*i}],  %fA{i};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e76d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(84):\n",
    "#   for _ in range(20):\n",
    "#     print(f\"    fma.rn.f32 %fA{i}, %fB{i}, %fC{i}, %fA{i}; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f53c9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(84): \n",
    "#   print(f\"mov.f32 %fC{i}, {(3*i/100)};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17ae7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "# Switched from 'from cuda import cuda' to 'cuda.bindings.driver' to fix deprecation warning\n",
    "from cuda.bindings import driver as cuda\n",
    "\n",
    "def check_cuda_errors(result):\n",
    "    \"\"\"Helper to check CUDA driver API results.\"\"\"\n",
    "    if isinstance(result, tuple):\n",
    "        err = result[0]\n",
    "        if len(result) > 1:\n",
    "            val = result[1]\n",
    "        else:\n",
    "            val = None\n",
    "    else:\n",
    "        err = result\n",
    "        val = None\n",
    "\n",
    "    if err != cuda.CUresult.CUDA_SUCCESS:\n",
    "        raise RuntimeError(f\"CUDA Error: {err}\")\n",
    "    return val\n",
    "\n",
    "def run_cuda_kernel(ptx_path, kernel_name):\n",
    "    # --- Configuration ---\n",
    "    # Launch parameters stay hardcoded as requested\n",
    "    NUM_THREADS = 1  # One Warp\n",
    "    REGS_PER_THREAD = 84\n",
    "\n",
    "    try:\n",
    "        # --- 1. Initialize CUDA ---\n",
    "        check_cuda_errors(cuda.cuInit(0))\n",
    "        device = check_cuda_errors(cuda.cuDeviceGet(0))\n",
    "        context = check_cuda_errors(cuda.cuCtxCreate(0, device))\n",
    "        print(f\"Context created on device: {device}\")\n",
    "\n",
    "        # --- 2. Load PTX Module ---\n",
    "        try:\n",
    "            with open(ptx_path, \"rb\") as f:\n",
    "                ptx_data = f.read()\n",
    "            # Ensure null-termination for the driver\n",
    "            if not ptx_data.endswith(b'\\0'):\n",
    "                ptx_data += b'\\0'\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Could not find '{ptx_path}'. Make sure it's in the same directory.\")\n",
    "            return None, None, None\n",
    "\n",
    "        module = check_cuda_errors(cuda.cuModuleLoadData(ptx_data))\n",
    "        kernel = check_cuda_errors(cuda.cuModuleGetFunction(module, kernel_name.encode(\"utf-8\")))\n",
    "\n",
    "        # --- 3. Allocate Host Memory ---\n",
    "        # Timestamps\n",
    "        h_start_clock = np.zeros(NUM_THREADS, dtype=np.uint64)\n",
    "        h_end_clock = np.zeros(NUM_THREADS, dtype=np.uint64)\n",
    "        \n",
    "        # Results: 32 threads * 84 registers * 4 bytes\n",
    "        total_floats = NUM_THREADS * REGS_PER_THREAD\n",
    "        h_results = np.zeros(total_floats, dtype=np.float32)\n",
    "\n",
    "        print(f\"Allocating {h_results.nbytes / 1024:.2f} KB for results...\")\n",
    "\n",
    "        # --- 4. Allocate Device Memory ---\n",
    "        d_start_clock = check_cuda_errors(cuda.cuMemAlloc(h_start_clock.nbytes))\n",
    "        d_end_clock = check_cuda_errors(cuda.cuMemAlloc(h_end_clock.nbytes))\n",
    "        d_results = check_cuda_errors(cuda.cuMemAlloc(h_results.nbytes))\n",
    "\n",
    "        # --- 5. Prepare Kernel Arguments ---\n",
    "        # The driver API expects an array of pointers to the arguments.\n",
    "        # We wrap the device pointers in numpy arrays so we can get their address.\n",
    "        arg_start = np.array([d_start_clock], dtype=np.uint64)\n",
    "        arg_end = np.array([d_end_clock], dtype=np.uint64)\n",
    "        arg_res = np.array([d_results], dtype=np.uint64)\n",
    "\n",
    "        args = np.array([\n",
    "            arg_start.ctypes.data,\n",
    "            arg_end.ctypes.data,\n",
    "            arg_res.ctypes.data\n",
    "        ], dtype=np.uint64)\n",
    "\n",
    "        # --- 6. Launch Kernel ---\n",
    "        print(f\"Launching Kernel '{kernel_name}' from '{ptx_path}'...\")\n",
    "        check_cuda_errors(cuda.cuLaunchKernel(\n",
    "            kernel,\n",
    "            1, 1, 1,            # Grid (1 block)\n",
    "            NUM_THREADS, 1, 1,  # Block (32 threads)\n",
    "            0,                  # Shared Mem\n",
    "            0,                  # Stream\n",
    "            args.ctypes.data,   # Kernel Arguments\n",
    "            0                   # Extra (NULL)\n",
    "        ))\n",
    "\n",
    "        # Synchronize\n",
    "        check_cuda_errors(cuda.cuCtxSynchronize())\n",
    "\n",
    "        # --- 7. Copy Back Results ---\n",
    "        check_cuda_errors(cuda.cuMemcpyDtoH(h_start_clock.ctypes.data, d_start_clock, h_start_clock.nbytes))\n",
    "        check_cuda_errors(cuda.cuMemcpyDtoH(h_end_clock.ctypes.data, d_end_clock, h_end_clock.nbytes))\n",
    "        check_cuda_errors(cuda.cuMemcpyDtoH(h_results.ctypes.data, d_results, h_results.nbytes))\n",
    "\n",
    "        # --- Cleanup ---\n",
    "        # IMPORTANT: Destroy context to free GPU memory for the next run\n",
    "        print(\"Destroying context...\")\n",
    "        check_cuda_errors(cuda.cuCtxDestroy(context))\n",
    "        \n",
    "        # --- 8. Return Results ---\n",
    "        # Return the three numpy arrays\n",
    "        return h_start_clock, h_end_clock, h_results\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbb9b620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context created on device: <CUdevice 0>\n",
      "Allocating 0.33 KB for results...\n",
      "Launching Kernel 'fma_max_pressure' from '/root/CudaNotebooks2/ILP_DEMON/ilp_good.ptx'...\n",
      "Destroying context...\n"
     ]
    }
   ],
   "source": [
    "starts_good, ends_good, res_good = run_cuda_kernel(\"/root/CudaNotebooks2/ILP_DEMON/ilp_good.ptx\", \"fma_max_pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52bd4bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context created on device: <CUdevice 0>\n",
      "Allocating 0.33 KB for results...\n",
      "Launching Kernel 'fma_retarded_pressure' from '/root/CudaNotebooks2/ILP_DEMON/ilp_bad.ptx'...\n",
      "Destroying context...\n"
     ]
    }
   ],
   "source": [
    "starts_bad, ends_bad, res_bad = run_cuda_kernel(\"/root/CudaNotebooks2/ILP_DEMON/ilp_bad.ptx\", \"fma_retarded_pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fffeaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(res_bad,res_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcb3f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_good = ends_good - starts_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87a2eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_bad = ends_bad - starts_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aa2b3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2709], dtype=uint64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344183f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2868], dtype=uint64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49258928",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_fmas = np.array([84*20]) \n",
    "N_fmas_per_clock_good = N_fmas/times_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b59d2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_fmas_per_clock_bad = N_fmas/times_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10ceb141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58577406])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_fmas_per_clock_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e63708fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62015504])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_fmas_per_clock_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf74cca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 1: True Throughput Kernel (Fat ASM Block)...\n",
      "Launching 2: Latency Bound Kernel (Swapped Loops)...\n",
      "\n",
      "--- Benchmark (N=64, Reps=500000) ---\n",
      "Total FMA Ops per kernel: 32000000\n",
      "\n",
      "[1. Throughput Bound Loop (Pipelined)]\n",
      "Total Clocks:  12344243\n",
      "Clocks / FMA:  0.385758\n",
      "\n",
      "[2. Latency Bound Loop (Stalled)]\n",
      "Total Clocks:  134320234\n",
      "Clocks / FMA:  4.197507\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Use N=64 as you requested\n",
    "constexpr int N = 64;\n",
    "constexpr int reps = 500000;\n",
    "\n",
    "__device__ __forceinline__ unsigned long long get_clock64() {\n",
    "    unsigned long long clock_val;\n",
    "    asm volatile(\"mov.u64 %0, %%clock64;\" : \"=l\"(clock_val));\n",
    "    return clock_val;\n",
    "}\n",
    "\n",
    "// --- KERNEL 1: The \"Throughput Bound\" Loop (REALLY GOOD) ---\n",
    "// Outer loop is 'reps'. Inner loop is one fat asm block of 64\n",
    "// independent FMA instructions.\n",
    "// This is bound by FMA THROUGHPUT.\n",
    "__global__ void kernel_ThroughputBound(float *A, float *B, float *C, unsigned long long *g_start, unsigned long long *g_end) {\n",
    "    \n",
    "    // Allocate 3 register arrays, 1D, size N\n",
    "    float rA[N], rB[N];\n",
    "    float rC[N] = {0.0f};\n",
    "\n",
    "    // Pre-load all registers\n",
    "    for(int i=0; i<N; ++i) { \n",
    "        rA[i] = A[i];\n",
    "        rB[i] = B[i];\n",
    "    }\n",
    "    __syncthreads(); // Ensure loads are done\n",
    "\n",
    "    *g_start = get_clock64();\n",
    "\n",
    "    // Outer loop is over N_iter (reps)\n",
    "    for (int repeat = 0; repeat < reps; repeat++) {\n",
    "        \n",
    "        // This single block contains 64 independent FMA operations.\n",
    "        // The hardware FMA pipeline will be full.\n",
    "        // The constraint list is huge (64 outputs, 128 inputs)\n",
    "        asm volatile (\n",
    "            \"fma.rn.f32 %0, %1, %2, %0; \\n\\t\" \n",
    "            \"fma.rn.f32 %3, %4, %5, %3; \\n\\t\" \n",
    "            \"fma.rn.f32 %6, %7, %8, %6; \\n\\t\" \n",
    "            \"fma.rn.f32 %9, %10, %11, %9; \\n\\t\" \n",
    "            \"fma.rn.f32 %12, %13, %14, %12; \\n\\t\" \n",
    "            \"fma.rn.f32 %15, %16, %17, %15; \\n\\t\" \n",
    "            \"fma.rn.f32 %18, %19, %20, %18; \\n\\t\" \n",
    "            \"fma.rn.f32 %21, %22, %23, %21; \\n\\t\" \n",
    "            \"fma.rn.f32 %24, %25, %26, %24; \\n\\t\" \n",
    "            \"fma.rn.f32 %27, %28, %29, %27; \\n\\t\" \n",
    "            \"fma.rn.f32 %30, %31, %32, %30; \\n\\t\" \n",
    "            \"fma.rn.f32 %33, %34, %35, %33; \\n\\t\" \n",
    "            \"fma.rn.f32 %36, %37, %38, %36; \\n\\t\" \n",
    "            \"fma.rn.f32 %39, %40, %41, %39; \\n\\t\" \n",
    "            \"fma.rn.f32 %42, %43, %44, %42; \\n\\t\" \n",
    "            \"fma.rn.f32 %45, %46, %47, %45; \\n\\t\" \n",
    "            \"fma.rn.f32 %48, %49, %50, %48; \\n\\t\" \n",
    "            \"fma.rn.f32 %51, %52, %53, %51; \\n\\t\" \n",
    "            \"fma.rn.f32 %54, %55, %56, %54; \\n\\t\" \n",
    "            \"fma.rn.f32 %57, %58, %59, %57; \\n\\t\" \n",
    "            \"fma.rn.f32 %60, %61, %62, %60; \\n\\t\" \n",
    "            \"fma.rn.f32 %63, %64, %65, %63; \\n\\t\" \n",
    "            \"fma.rn.f32 %66, %67, %68, %66; \\n\\t\" \n",
    "            \"fma.rn.f32 %69, %70, %71, %69; \\n\\t\" \n",
    "            \"fma.rn.f32 %72, %73, %74, %72; \\n\\t\" \n",
    "            \"fma.rn.f32 %75, %76, %77, %75; \\n\\t\" \n",
    "            \"fma.rn.f32 %78, %79, %80, %78; \\n\\t\" \n",
    "            \"fma.rn.f32 %81, %82, %83, %81; \\n\\t\" \n",
    "            \"fma.rn.f32 %84, %85, %86, %84; \\n\\t\" \n",
    "            \"fma.rn.f32 %87, %88, %89, %87; \\n\\t\" \n",
    "            \"fma.rn.f32 %90, %91, %92, %90; \\n\\t\" \n",
    "            \"fma.rn.f32 %93, %94, %95, %93; \\n\\t\" \n",
    "            \"fma.rn.f32 %96, %97, %98, %96; \\n\\t\" \n",
    "            \"fma.rn.f32 %99, %100, %101, %99; \\n\\t\" \n",
    "            \"fma.rn.f32 %102, %103, %104, %102; \\n\\t\" \n",
    "            \"fma.rn.f32 %105, %106, %107, %105; \\n\\t\" \n",
    "            \"fma.rn.f32 %108, %109, %110, %108; \\n\\t\" \n",
    "            \"fma.rn.f32 %111, %112, %113, %111; \\n\\t\" \n",
    "            \"fma.rn.f32 %114, %115, %116, %114; \\n\\t\" \n",
    "            \"fma.rn.f32 %117, %118, %119, %117; \\n\\t\" \n",
    "            \"fma.rn.f32 %120, %121, %122, %120; \\n\\t\" \n",
    "            \"fma.rn.f32 %123, %124, %125, %123; \\n\\t\" \n",
    "            \"fma.rn.f32 %126, %127, %128, %126; \\n\\t\" \n",
    "            \"fma.rn.f32 %129, %130, %131, %129; \\n\\t\" \n",
    "            \"fma.rn.f32 %132, %133, %134, %132; \\n\\t\" \n",
    "            \"fma.rn.f32 %135, %136, %137, %135; \\n\\t\" \n",
    "            \"fma.rn.f32 %138, %139, %140, %138; \\n\\t\" \n",
    "            \"fma.rn.f32 %141, %142, %143, %141; \\n\\t\" \n",
    "            \"fma.rn.f32 %144, %145, %146, %144; \\n\\t\" \n",
    "            \"fma.rn.f32 %147, %148, %149, %147; \\n\\t\" \n",
    "            \"fma.rn.f32 %150, %151, %152, %150; \\n\\t\" \n",
    "            \"fma.rn.f32 %153, %154, %155, %153; \\n\\t\" \n",
    "            \"fma.rn.f32 %156, %157, %158, %156; \\n\\t\" \n",
    "            \"fma.rn.f32 %159, %160, %161, %159; \\n\\t\" \n",
    "            \"fma.rn.f32 %162, %163, %164, %162; \\n\\t\" \n",
    "            \"fma.rn.f32 %165, %166, %167, %165; \\n\\t\" \n",
    "            \"fma.rn.f32 %168, %169, %170, %168; \\n\\t\" \n",
    "            \"fma.rn.f32 %171, %172, %173, %171; \\n\\t\" \n",
    "            \"fma.rn.f32 %174, %175, %176, %174; \\n\\t\" \n",
    "            \"fma.rn.f32 %177, %178, %179, %177; \\n\\t\" \n",
    "            \"fma.rn.f32 %180, %181, %182, %180; \\n\\t\" \n",
    "            \"fma.rn.f32 %183, %184, %185, %183; \\n\\t\" \n",
    "            \"fma.rn.f32 %186, %187, %188, %186; \\n\\t\" \n",
    "            \"fma.rn.f32 %189, %190, %191, %189; \\n\\t\"\n",
    "            // --- Output Operands (Read+Write) ---\n",
    "            : \"+f\"(rC[0]),  \"+f\"(rC[1]), \"+f\"(rC[2]), \"+f\"(rC[3]), \n",
    "              \"+f\"(rC[4]),  \"+f\"(rC[5]), \"+f\"(rC[6]), \"+f\"(rC[7]), \n",
    "              \"+f\"(rC[8]),  \"+f\"(rC[9]), \"+f\"(rC[10]), \"+f\"(rC[11]), \n",
    "              \"+f\"(rC[12]),  \"+f\"(rC[13]), \"+f\"(rC[14]), \"+f\"(rC[15]), \n",
    "              \"+f\"(rC[16]),  \"+f\"(rC[17]), \"+f\"(rC[18]), \"+f\"(rC[19]), \n",
    "              \"+f\"(rC[20]),  \"+f\"(rC[21]), \"+f\"(rC[22]), \"+f\"(rC[23]), \n",
    "              \"+f\"(rC[24]),  \"+f\"(rC[25]), \"+f\"(rC[26]), \"+f\"(rC[27]), \n",
    "              \"+f\"(rC[28]),  \"+f\"(rC[29]), \"+f\"(rC[30]), \"+f\"(rC[31]), \n",
    "              \"+f\"(rC[32]),  \"+f\"(rC[33]), \"+f\"(rC[34]), \"+f\"(rC[35]), \n",
    "              \"+f\"(rC[36]),  \"+f\"(rC[37]), \"+f\"(rC[38]), \"+f\"(rC[39]), \n",
    "              \"+f\"(rC[40]),  \"+f\"(rC[41]), \"+f\"(rC[42]), \"+f\"(rC[43]), \n",
    "              \"+f\"(rC[44]),  \"+f\"(rC[45]), \"+f\"(rC[46]), \"+f\"(rC[47]), \n",
    "              \"+f\"(rC[48]),  \"+f\"(rC[49]), \"+f\"(rC[50]), \"+f\"(rC[51]), \n",
    "              \"+f\"(rC[52]),  \"+f\"(rC[53]), \"+f\"(rC[54]), \"+f\"(rC[55]), \n",
    "              \"+f\"(rC[56]),  \"+f\"(rC[57]), \"+f\"(rC[58]), \"+f\"(rC[59]), \n",
    "              \"+f\"(rC[60]),  \"+f\"(rC[61]), \"+f\"(rC[62]), \"+f\"(rC[63])\n",
    "            \n",
    "            // --- Input Operands (Read-Only) ---\n",
    "            : \"f\"(rA[0]),  \"f\"(rB[0]), \"f\"(rA[1]), \"f\"(rB[1]), \n",
    "              \"f\"(rA[2]),  \"f\"(rB[2]), \"f\"(rA[3]), \"f\"(rB[3]), \n",
    "              \"f\"(rA[4]),  \"f\"(rB[4]), \"f\"(rA[5]), \"f\"(rB[5]), \n",
    "              \"f\"(rA[6]),  \"f\"(rB[6]), \"f\"(rA[7]), \"f\"(rB[7]), \n",
    "              \"f\"(rA[8]),  \"f\"(rB[8]), \"f\"(rA[9]), \"f\"(rB[9]), \n",
    "              \"f\"(rA[10]),  \"f\"(rB[10]), \"f\"(rA[11]), \"f\"(rB[11]), \n",
    "              \"f\"(rA[12]),  \"f\"(rB[12]), \"f\"(rA[13]), \"f\"(rB[13]), \n",
    "              \"f\"(rA[14]),  \"f\"(rB[14]), \"f\"(rA[15]), \"f\"(rB[15]), \n",
    "              \"f\"(rA[16]),  \"f\"(rB[16]), \"f\"(rA[17]), \"f\"(rB[17]), \n",
    "              \"f\"(rA[18]),  \"f\"(rB[18]), \"f\"(rA[19]), \"f\"(rB[19]), \n",
    "              \"f\"(rA[20]),  \"f\"(rB[20]), \"f\"(rA[21]), \"f\"(rB[21]), \n",
    "              \"f\"(rA[22]),  \"f\"(rB[22]), \"f\"(rA[23]), \"f\"(rB[23]), \n",
    "              \"f\"(rA[24]),  \"f\"(rB[24]), \"f\"(rA[25]), \"f\"(rB[25]), \n",
    "              \"f\"(rA[26]),  \"f\"(rB[26]), \"f\"(rA[27]), \"f\"(rB[27]), \n",
    "              \"f\"(rA[28]),  \"f\"(rB[28]), \"f\"(rA[29]), \"f\"(rB[29]), \n",
    "              \"f\"(rA[30]),  \"f\"(rB[30]), \"f\"(rA[31]), \"f\"(rB[31]), \n",
    "              \"f\"(rA[32]),  \"f\"(rB[32]), \"f\"(rA[33]), \"f\"(rB[33]), \n",
    "              \"f\"(rA[34]),  \"f\"(rB[34]), \"f\"(rA[35]), \"f\"(rB[35]), \n",
    "              \"f\"(rA[36]),  \"f\"(rB[36]), \"f\"(rA[37]), \"f\"(rB[37]), \n",
    "              \"f\"(rA[38]),  \"f\"(rB[38]), \"f\"(rA[39]), \"f\"(rB[39]), \n",
    "              \"f\"(rA[40]),  \"f\"(rB[40]), \"f\"(rA[41]), \"f\"(rB[41]), \n",
    "              \"f\"(rA[42]),  \"f\"(rB[42]), \"f\"(rA[43]), \"f\"(rB[43]), \n",
    "              \"f\"(rA[44]),  \"f\"(rB[44]), \"f\"(rA[45]), \"f\"(rB[45]), \n",
    "              \"f\"(rA[46]),  \"f\"(rB[46]), \"f\"(rA[47]), \"f\"(rB[47]), \n",
    "              \"f\"(rA[48]),  \"f\"(rB[48]), \"f\"(rA[49]), \"f\"(rB[49]), \n",
    "              \"f\"(rA[50]),  \"f\"(rB[50]), \"f\"(rA[51]), \"f\"(rB[51]), \n",
    "              \"f\"(rA[52]),  \"f\"(rB[52]), \"f\"(rA[53]), \"f\"(rB[53]), \n",
    "              \"f\"(rA[54]),  \"f\"(rB[54]), \"f\"(rA[55]), \"f\"(rB[55]), \n",
    "              \"f\"(rA[56]),  \"f\"(rB[56]), \"f\"(rA[57]), \"f\"(rB[57]), \n",
    "              \"f\"(rA[58]),  \"f\"(rB[58]), \"f\"(rA[59]), \"f\"(rB[59]), \n",
    "              \"f\"(rA[60]),  \"f\"(rB[60]), \"f\"(rA[61]), \"f\"(rB[61]), \n",
    "              \"f\"(rA[62]),  \"f\"(rB[62]), \"f\"(rA[63]), \"f\"(rB[63])\n",
    "        );\n",
    "    }\n",
    "    \n",
    "   \n",
    "    __syncthreads();\n",
    "     *g_end = get_clock64();\n",
    "    for(int i=0; i<N; ++i) { C[i] = rC[i]; }\n",
    "}\n",
    "\n",
    "\n",
    "// --- KERNEL 2: The \"Latency Bound\" Loop (REALLY BAD) ---\n",
    "// Outer loop is over N (indices). Inner loop is 'reps'.\n",
    "// The asm block is *inside* the 'reps' loop, creating a\n",
    "// serial dependency chain.\n",
    "// This is bound by FMA LATENCY.\n",
    "__global__ void kernel_LatencyBound(float *A, float *B, float *C, unsigned long long *g_start, unsigned long long *g_end) {\n",
    "    \n",
    "    float rA[N], rB[N];\n",
    "    float rC[N] = {0.0f};\n",
    "\n",
    "    // Pre-load all registers\n",
    "    for(int i=0; i<N; ++i) { \n",
    "        rA[i] = A[i];\n",
    "        rB[i] = B[i];\n",
    "    }\n",
    "    __syncthreads(); // Ensure loads are done\n",
    "\n",
    "    *g_start = get_clock64();\n",
    "\n",
    "    // Outer loop is over the 64 indices\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        // Inner loop is over N_iter (reps)\n",
    "        for (int repeat = 0; repeat < reps; repeat++) {\n",
    "            \n",
    "            // This asm block is executed 'reps' times for EACH 'i'.\n",
    "            // It creates a long dependency chain on rC[i].\n",
    "            // The pipeline will stall on every single iteration.\n",
    "            asm volatile (\n",
    "                \"fma.rn.f32 %0, %1, %2, %0;\"\n",
    "                : \"+f\"(rC[i])   // %0: Read+Write (e.g., rC[0])\n",
    "                : \"f\"(rA[i]),   // %1: Read (e.g., rA[0])\n",
    "                  \"f\"(rB[i])    // %2: Read (e.g., rB[0])\n",
    "            );\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    __syncthreads();\n",
    "    *g_end = get_clock64();\n",
    "    for(int i=0; i<N; ++i) { C[i + N] = rC[i]; } // Store in second half\n",
    "}\n",
    "\n",
    "\n",
    "int main() {\n",
    "    float *h_A, *h_B, *h_C;\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    unsigned long long h_start[2], h_end[2];\n",
    "    unsigned long long *d_start, *d_end;\n",
    "    \n",
    "    // N=64\n",
    "    size_t vec_bytes = N * sizeof(float);\n",
    "    size_t c_bytes   = vec_bytes * 2; // 2 slots for output\n",
    "    size_t clock_bytes = sizeof(unsigned long long) * 2;\n",
    "\n",
    "    h_A = (float*)malloc(vec_bytes);\n",
    "    h_B = (float*)malloc(vec_bytes);\n",
    "    h_C = (float*)malloc(c_bytes);\n",
    "\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_A[i] = (float)(i + 1);\n",
    "        h_B[i] = (float)(i + 1);\n",
    "    }\n",
    "\n",
    "    cudaMalloc(&d_A, vec_bytes);\n",
    "    cudaMalloc(&d_B, vec_bytes);\n",
    "    cudaMalloc(&d_C, c_bytes);\n",
    "    cudaMalloc(&d_start, clock_bytes);\n",
    "    cudaMalloc(&d_end, clock_bytes);\n",
    "\n",
    "    cudaMemcpy(d_A, h_A, vec_bytes, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, vec_bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // --- Launch Kernel 1 (Throughput Bound) ---\n",
    "    printf(\"Launching 1: True Throughput Kernel (Fat ASM Block)...\\n\");\n",
    "    kernel_ThroughputBound<<<1,1>>>(d_A, d_B, d_C, d_start, d_end);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // --- Launch Kernel 2 (Latency Bound) ---\n",
    "    printf(\"Launching 2: Latency Bound Kernel (Swapped Loops)...\\n\");\n",
    "    kernel_LatencyBound<<<1,1>>>(d_A, d_B, d_C, d_start + 1, d_end + 1);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // # Copy back results\n",
    "    cudaMemcpy(h_C, d_C, c_bytes, cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(h_start, d_start, clock_bytes, cudaMemcpyDeviceToHost); \n",
    "    cudaMemcpy(h_end, d_end, clock_bytes, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // --- Print clock results ---\n",
    "    unsigned long long elapsed_throughput = h_end[0] - h_start[0];\n",
    "    unsigned long long elapsed_latency    = h_end[1] - h_start[1];\n",
    "    \n",
    "    // Total FMA ops is (N * reps) for both kernels.\n",
    "    unsigned long long total_ops = (unsigned long long)N * reps;\n",
    "    \n",
    "    double clocks_per_op_throughput = static_cast<double>(elapsed_throughput) / total_ops;\n",
    "    double clocks_per_op_latency    = static_cast<double>(elapsed_latency) / total_ops;\n",
    "    \n",
    "    printf(\"\\n--- Benchmark (N=%d, Reps=%d) ---\\n\", N, reps);\n",
    "    printf(\"Total FMA Ops per kernel: %llu\\n\", total_ops);\n",
    "\n",
    "    printf(\"\\n[1. Throughput Bound Loop (Pipelined)]\\n\");\n",
    "    printf(\"Total Clocks:  %llu\\n\", elapsed_throughput);\n",
    "    printf(\"Clocks / FMA:  %f\\n\", clocks_per_op_throughput);\n",
    "\n",
    "    printf(\"\\n[2. Latency Bound Loop (Stalled)]\\n\");\n",
    "    printf(\"Total Clocks:  %llu\\n\", elapsed_latency);\n",
    "    printf(\"Clocks / FMA:  %f\\n\", clocks_per_op_latency);\n",
    "    printf(\"----------------------------------------\\n\");\n",
    "\n",
    "    // #Cleanup\n",
    "    cudaFree(d_end);\n",
    "    cudaFree(d_start); \n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3aa9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
