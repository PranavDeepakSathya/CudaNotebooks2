{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700853b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MemoryState:\n",
    "    def __init__(self, name, unit_access_cost):\n",
    "        self.name = name\n",
    "        self.unit_access_cost = unit_access_cost\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}(Cost={self.unit_access_cost})\"\n",
    "\n",
    "# --- Define Your Hierarchy ---\n",
    "GMEM  = MemoryState(\"GMEM\",  100.0) # Expensive to read\n",
    "DSMEM = MemoryState(\"DSMEM\", 20.0)  # Medium\n",
    "SMEM  = MemoryState(\"SMEM\",  10.0)  # Cheap\n",
    "REG   = MemoryState(\"REG\",   1.0)   # Fastest\n",
    "\n",
    "class AugmentedTensor:\n",
    "    def __init__(self, data, state):\n",
    "        \"\"\"\n",
    "        :param data: The actual numpy array (or shape, if you want empty)\n",
    "        :param state: MemoryState object (holds the cost logic)\n",
    "        \"\"\"\n",
    "        # If user passes just a shape, we create zeros, otherwise use the array\n",
    "        if isinstance(data, (tuple, list)):\n",
    "            self.data = np.zeros(data)\n",
    "        else:\n",
    "            self.data = np.array(data)\n",
    "            \n",
    "        self.state = state\n",
    "        self.total_cost = 0.0\n",
    "\n",
    "    def load(self, source_tensor):\n",
    "        \"\"\"\n",
    "        B.load(A) -> Copies data from A to B.\n",
    "        \n",
    "        The COST is incurred by A (the Source), because we are \n",
    "        accessing A's memory to read it.\n",
    "        \"\"\"\n",
    "        # 1. Check if source is actually an AugmentedTensor (or a slice of one)\n",
    "        if not isinstance(source_tensor, AugmentedTensor):\n",
    "            raise ValueError(\"Source must be an AugmentedTensor\")\n",
    "\n",
    "        # 2. Incur Cost on the SOURCE\n",
    "        # Cost = (Number of Elements Accessed) * (Source's Unit Cost)\n",
    "        access_size = source_tensor.data.size\n",
    "        cost_incurred = access_size * source_tensor.state.unit_access_cost\n",
    "        \n",
    "        source_tensor.total_cost += cost_incurred\n",
    "        \n",
    "        # 3. Actually Move the Data (Numpy Copy)\n",
    "        # We assume shapes match for this primitive load, or broadcast works\n",
    "        self.data[:] = source_tensor.data\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Allows slicing: A[0:10]. \n",
    "        Returns a temporary AugmentedTensor view so we can pass it to load().\n",
    "        We share the 'total_cost' accumulator with the parent so the parent gets charged.\n",
    "        \"\"\"\n",
    "        sliced_data = self.data[key]\n",
    "        \n",
    "        # Create a 'View' Tensor\n",
    "        # It needs to point back to the original to charge costs? \n",
    "        # For simplicity in this snippet, let's just make a new object \n",
    "        # but manually link the cost accounting if needed. \n",
    "        # ACTUALLY: The prompt asks to incur cost on the tensor itself.\n",
    "        # If I slice A, and pass the slice to load, I need A to be charged.\n",
    "        \n",
    "        # Implementation Trick: The \"View\" is just a new Tensor, but we \n",
    "        # need to handle the charging manually or link them.\n",
    "        # Let's keep it simple: The 'load' function calculates size from the input.\n",
    "        # If the input is a slice, it has a smaller size.\n",
    "        # But we want the ORIGINAL A to be charged? \n",
    "        # YOU SAID: \"A_gmem(slice) ... INCURR A COST ON A_GMEM\"\n",
    "        \n",
    "        # To support this strictly:\n",
    "        return TensorSlice(self, key)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[{self.state.name}] Shape:{self.data.shape} | AccCost: {self.total_cost}\"\n",
    "\n",
    "\n",
    "class TensorSlice(AugmentedTensor):\n",
    "    \"\"\"\n",
    "    Helper class to handle A[slice].\n",
    "    When this is passed to load(), we charge the PARENT.\n",
    "    \"\"\"\n",
    "    def __init__(self, parent, slice_key):\n",
    "        self.parent = parent\n",
    "        self.data = parent.data[slice_key] # The actual data view\n",
    "        self.state = parent.state # Same state as parent\n",
    "\n",
    "    def report_access(self):\n",
    "        \"\"\" Charge the parent for this slice's size \"\"\"\n",
    "        cost = self.data.size * self.state.unit_access_cost\n",
    "        self.parent.total_cost += cost\n",
    "\n",
    "# --- Re-implementing load to handle the Slice Wrapper ---\n",
    "def smart_load(self, source):\n",
    "    if isinstance(source, TensorSlice):\n",
    "        # Charge the parent of the slice\n",
    "        source.report_access()\n",
    "        # Copy data\n",
    "        self.data[:] = source.data\n",
    "    elif isinstance(source, AugmentedTensor):\n",
    "        # Charge the full tensor\n",
    "        cost = source.data.size * source.state.unit_access_cost\n",
    "        source.total_cost += cost\n",
    "        self.data[:] = source.data\n",
    "    else:\n",
    "        raise ValueError(\"Unknown source type\")\n",
    "\n",
    "# Patching the method for the demo\n",
    "AugmentedTensor.load = smart_load\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "#  USER DEMO\n",
    "# ==========================================\n",
    "\n",
    "# 1. Setup Data\n",
    "A_gmem = AugmentedTensor(np.ones((100, 100)), GMEM) # 100x100 ones\n",
    "B_smem = AugmentedTensor(np.zeros((10, 100)), SMEM) # Smaller buffer\n",
    "\n",
    "print(\"--- Initial State ---\")\n",
    "print(\"A (Source):\", A_gmem)\n",
    "print(\"B (Dest):  \", B_smem)\n",
    "\n",
    "# 2. Perform the Load\n",
    "# \"B_smem.load(A_gmem(slice))\"\n",
    "# We act on a slice of A (first 10 rows)\n",
    "B_smem.load(A_gmem[0:10]) \n",
    "\n",
    "print(\"\\n--- After Load ---\")\n",
    "print(\"A (Source):\", A_gmem) # Should show cost: 1000 elements * 100 cost = 100,000\n",
    "print(\"B (Dest):  \", B_smem) # Should have data, Cost 0 (since it was written to, not read from)\n",
    "print(\"\\nB Data Sample (First row):\", B_smem.data[0, :5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
