{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700853b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial State ---\n",
      "A (Source): [GMEM] Shape:(100, 100) | AccCost: 0.0\n",
      "B (Dest):   [SMEM] Shape:(10, 100) | AccCost: 0.0\n",
      "\n",
      "--- After Load ---\n",
      "A (Source): [GMEM] Shape:(100, 100) | AccCost: 100000.0\n",
      "B (Dest):   [SMEM] Shape:(10, 100) | AccCost: 0.0\n",
      "\n",
      "B Data Sample (First row): [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MemoryState:\n",
    "    def __init__(self, name, unit_access_cost, capacity_bytes):\n",
    "        self.name = name\n",
    "        self.unit_access_cost = unit_access_cost\n",
    "        self.capacity_bytes = capacity_bytes\n",
    "\n",
    "    def __repr__(self):\n",
    "        # Format bytes to KB/MB for readability\n",
    "        if self.capacity_bytes >= 1024**3:\n",
    "            cap_str = f\"{self.capacity_bytes / 1024**3:.1f} GB\"\n",
    "        elif self.capacity_bytes >= 1024**2:\n",
    "            cap_str = f\"{self.capacity_bytes / 1024**2:.1f} MB\"\n",
    "        elif self.capacity_bytes >= 1024:\n",
    "            cap_str = f\"{self.capacity_bytes / 1024:.1f} KB\"\n",
    "        else:\n",
    "            cap_str = f\"{self.capacity_bytes} B\"\n",
    "            \n",
    "        return f\"{self.name}(Cost={self.unit_access_cost}, Max={cap_str})\"\n",
    "\n",
    "# --- Define Your Hierarchy (Approx Hopper Capacities) ---\n",
    "# GMEM: Effectively infinite (80GB+)\n",
    "GMEM  = MemoryState(\"GMEM\",  100.0, capacity_bytes=80 * 1024**3) \n",
    "\n",
    "# DSMEM: Distributed SMEM (Cluster level) - large but not infinite\n",
    "DSMEM = MemoryState(\"DSMEM\", 20.0,  capacity_bytes=100 * 1024**2) \n",
    "\n",
    "# SMEM: Hopper has ~227KB max per SM. Let's be strict.\n",
    "SMEM  = MemoryState(\"SMEM\",  10.0,  capacity_bytes=227 * 1024) \n",
    "\n",
    "# REG: 64K registers per SM (32-bit). Very tight constraint.\n",
    "REG   = MemoryState(\"REG\",   1.0,   capacity_bytes=64 * 1024 * 4) \n",
    "\n",
    "class AugmentedTensor:\n",
    "    def __init__(self, data, state):\n",
    "        \"\"\"\n",
    "        :param data: The actual numpy array (or shape, if you want empty)\n",
    "        :param state: MemoryState object (holds the cost logic)\n",
    "        \"\"\"\n",
    "        # 1. Initialize Data\n",
    "        if isinstance(data, (tuple, list)):\n",
    "            self.data = np.zeros(data) # Default float64, be careful!\n",
    "        else:\n",
    "            self.data = np.array(data)\n",
    "            \n",
    "        self.state = state\n",
    "        self.total_cost = 0.0\n",
    "\n",
    "        # 2. CAPACITY CHECK\n",
    "        tensor_bytes = self.data.nbytes\n",
    "        if tensor_bytes > self.state.capacity_bytes:\n",
    "            raise MemoryError(\n",
    "                f\"OOM: Cannot allocate tensor of size {tensor_bytes} bytes \"\n",
    "                f\"in {self.state.name} (Max: {self.state.capacity_bytes} bytes).\"\n",
    "            )\n",
    "\n",
    "    def load(self, source_tensor):\n",
    "        \"\"\"\n",
    "        B.load(A) -> Copies data from A to B.\n",
    "        The COST is incurred by A (the Source).\n",
    "        \"\"\"\n",
    "        # 1. Check if source is actually an AugmentedTensor (or a slice of one)\n",
    "        # Note: We do NOT need to check capacity here, because 'self' (B) \n",
    "        # was already checked during __init__.\n",
    "        \n",
    "        # 2. Incur Cost on the SOURCE\n",
    "        if isinstance(source_tensor, TensorSlice):\n",
    "            source_tensor.report_access()\n",
    "            # Copy data (Broadcasting/Slicing handled by numpy)\n",
    "            self.data[:] = source_tensor.data\n",
    "        elif isinstance(source_tensor, AugmentedTensor):\n",
    "            cost = source_tensor.data.size * source_tensor.state.unit_access_cost\n",
    "            source_tensor.total_cost += cost\n",
    "            self.data[:] = source_tensor.data\n",
    "        else:\n",
    "            raise ValueError(\"Source must be an AugmentedTensor or TensorSlice\")\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return TensorSlice(self, key)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[{self.state.name}] Shape:{self.data.shape} | Size:{self.data.nbytes} B | AccCost: {self.total_cost}\"\n",
    "\n",
    "\n",
    "class TensorSlice:\n",
    "    \"\"\"\n",
    "    Helper class to handle A[slice].\n",
    "    When this is passed to load(), we charge the PARENT.\n",
    "    \"\"\"\n",
    "    def __init__(self, parent, slice_key):\n",
    "        self.parent = parent\n",
    "        self.data = parent.data[slice_key] # The actual data view\n",
    "        self.state = parent.state # Same state as parent\n",
    "\n",
    "    def report_access(self):\n",
    "        \"\"\" Charge the parent for this slice's size \"\"\"\n",
    "        cost = self.data.size * self.state.unit_access_cost\n",
    "        self.parent.total_cost += cost\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "#  USER DEMO: Valid & Invalid Allocations\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- 1. Valid Allocation (GMEM) ---\")\n",
    "# 100x100 float64 = 80KB. Fits easily in GMEM.\n",
    "A_gmem = AugmentedTensor(np.ones((100, 100)), GMEM) \n",
    "print(A_gmem)\n",
    "\n",
    "print(\"\\n--- 2. Valid Allocation (SMEM) ---\")\n",
    "# 10x100 float64 = 8KB. Fits in 227KB SMEM.\n",
    "B_smem = AugmentedTensor(np.zeros((10, 100)), SMEM) \n",
    "print(B_smem)\n",
    "\n",
    "print(\"\\n--- 3. Perform Load ---\")\n",
    "B_smem.load(A_gmem[0:10])\n",
    "print(f\"Transfer Complete. Source Cost: {A_gmem.total_cost}\")\n",
    "\n",
    "print(\"\\n--- 4. INVALID Allocation (OOM Check) ---\")\n",
    "try:\n",
    "    # Try to fit a HUGE tensor into SMEM\n",
    "    # 200x200 float64 = 320,000 bytes (~312KB). \n",
    "    # Max SMEM is 227KB. This should FAIL.\n",
    "    huge_shape = (200, 200) \n",
    "    print(f\"Attempting to alloc {huge_shape} in SMEM...\")\n",
    "    C_fail = AugmentedTensor(np.zeros(huge_shape), SMEM)\n",
    "except MemoryError as e:\n",
    "    print(f\"SUCCESS: Caught Expected Error -> {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340daaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
