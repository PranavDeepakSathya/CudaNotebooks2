{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dfb55c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
      "  %reload_ext nvcc4jupyter\n"
     ]
    }
   ],
   "source": [
    "import cutlass\n",
    "import cutlass.cute as cute\n",
    "import cuda.bindings as cu\n",
    "%load_ext nvcc4jupyter\n",
    "\n",
    "from nvcc4jupyter import set_defaults\n",
    "set_defaults(compiler_args='-arch=sm_100a -Xptxas=-v -O0')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12ae1586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      " DEVICE: NVIDIA GeForce RTX 5090 (Compute 12.0)\n",
      "==========================================================\n",
      " [Compute]\n",
      "  Multiprocessors (SMs):       170\n",
      "  Max Threads per SM:          1536\n",
      "  Max Threads per Block:       1024\n",
      "  Warp Size:                   32\n",
      "\n",
      " [Registers]\n",
      "  Max 32-bit Regs per Block:   65536\n",
      "  Max 32-bit Regs per SM:      65536\n",
      "\n",
      " [Memory Hierarchy]\n",
      "  Smem per Block (Static):     48 KB\n",
      "  Smem per Block (Max Dyn):    99 KB\n",
      "  Smem per Multiprocessor:     100 KB\n",
      "  L2 Cache Size:               96 MB\n",
      "  Total Global Memory:         31.36 GB\n",
      "  Memory Bus Width:            512-bit\n",
      "==========================================================\n",
      "\n",
      "Occupancy Check:\n",
      "  Kernel: matmul\n",
      "  Block Size: 160 threads\n",
      "  Max Active Blocks per SM: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h> \n",
    "#include <cuda.h> \n",
    "#include <mma.h> \n",
    "#include <cuda_bf16.h>\n",
    "#include <cuda/barrier>\n",
    "\n",
    "using barrier = cuda::barrier<cuda::thread_scope_block>;\n",
    "namespace cde = cuda::device::experimental;\n",
    "\n",
    "constexpr int M = 4096;\n",
    "constexpr int N = 4096;\n",
    "constexpr int K = 4096;\n",
    "constexpr int bM = 32; \n",
    "constexpr int bN = 32; \n",
    "constexpr int bK = 32;\n",
    "\n",
    "__global__ void matmul(__nv_bfloat16* A, __nv_bfloat16 *B, __nv_bfloat16 *C, \n",
    "                        const __grid_constant__ CUtensorMap tensor_map_A, \n",
    "                        const __grid_constant__ CUtensorMap tensor_map_B)\n",
    "{\n",
    "  __shared__ alignas(128) __nv_bfloat16 S0[2][(bM*bK) + (bK*bN)]; \n",
    "  __shared__ alignas(128) __nv_bfloat16 S1[2][(bM*bK) + (bK*bN)]; \n",
    "\n",
    "  int t = threadIdx.x; \n",
    "\n",
    "  __shared__ barrier S0_E, S0_F, S1_E, S1_F; \n",
    "  if (t == 0)\n",
    "  {\n",
    "    init(&S0_E, blockDim.x);\n",
    "    init(&S1_E, blockDim.x);\n",
    "    init(&S0_F, blockDim.x);\n",
    "    init(&S1_F, blockDim.x);\n",
    "    cde::fence_proxy_async_shared_cta();\n",
    "  }\n",
    "  __syncthreads(); \n",
    "}\n",
    "\n",
    "void printDeviceStats(int deviceId) {\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, deviceId);\n",
    "\n",
    "    printf(\"\\n==========================================================\\n\");\n",
    "    printf(\" DEVICE: %s (Compute %d.%d)\\n\", prop.name, prop.major, prop.minor);\n",
    "    printf(\"==========================================================\\n\");\n",
    "    \n",
    "    // SM and Threading Info\n",
    "    printf(\" [Compute]\\n\");\n",
    "    printf(\"  Multiprocessors (SMs):       %d\\n\", prop.multiProcessorCount);\n",
    "    printf(\"  Max Threads per SM:          %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
    "    printf(\"  Max Threads per Block:       %d\\n\", prop.maxThreadsPerBlock);\n",
    "    printf(\"  Warp Size:                   %d\\n\", prop.warpSize);\n",
    "\n",
    "    // Registers\n",
    "    printf(\"\\n [Registers]\\n\");\n",
    "    printf(\"  Max 32-bit Regs per Block:   %d\\n\", prop.regsPerBlock);\n",
    "    printf(\"  Max 32-bit Regs per SM:      %d\\n\", prop.regsPerMultiprocessor);\n",
    "\n",
    "    // Shared Memory\n",
    "    printf(\"\\n [Memory Hierarchy]\\n\");\n",
    "    // Standard static shared mem limit\n",
    "    printf(\"  Smem per Block (Static):     %zu KB\\n\", prop.sharedMemPerBlock / 1024);\n",
    "    // Max possible shared mem per block (requires opt-in via cudaFuncSetAttribute)\n",
    "    printf(\"  Smem per Block (Max Dyn):    %zu KB\\n\", prop.sharedMemPerBlockOptin / 1024);\n",
    "    // Total shared memory available per SM (partitioned among blocks resident on that SM)\n",
    "    printf(\"  Smem per Multiprocessor:     %zu KB\\n\", prop.sharedMemPerMultiprocessor / 1024);\n",
    "    \n",
    "    // Global Memory & Cache\n",
    "    printf(\"  L2 Cache Size:               %d MB\\n\", prop.l2CacheSize / (1024 * 1024));\n",
    "    printf(\"  Total Global Memory:         %.2f GB\\n\", (float)prop.totalGlobalMem / (1024.0 * 1024.0 * 1024.0));\n",
    "    printf(\"  Memory Bus Width:            %d-bit\\n\", prop.memoryBusWidth);\n",
    "    //#printf(\"  Memory Clock Rate:           %.2f GHz\\n\", prop.memoryClockRate / 1.0e6);\n",
    "    \n",
    "    printf(\"==========================================================\\n\\n\");\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int deviceId = 0;\n",
    "    cudaGetDevice(&deviceId);\n",
    "    \n",
    "    // 1. Print the pretty stats\n",
    "    printDeviceStats(deviceId);\n",
    "\n",
    "    // 2. Your occupancy calculation\n",
    "    int numBlocks;\n",
    "    int blockSize = 5*32; \n",
    "    size_t dynamicSMemSize = 0; \n",
    "\n",
    "    cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "        &numBlocks, \n",
    "        matmul, \n",
    "        blockSize, \n",
    "        dynamicSMemSize\n",
    "    );\n",
    "\n",
    "    printf(\"Occupancy Check:\\n\");\n",
    "    printf(\"  Kernel: matmul\\n\");\n",
    "    printf(\"  Block Size: %d threads\\n\", blockSize);\n",
    "    printf(\"  Max Active Blocks per SM: %d\\n\", numBlocks);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c94f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4096 \n",
    "N = 4096 \n",
    "K = 4096\n",
    "wmma_m = 16\n",
    "wmma_n = 16\n",
    "wmma_k = 16\n",
    "n_warps = 32 \n",
    "n_buffers = 2\n",
    "n_stages_per_buffer = 8\n",
    "work_per_block = wmma_m*wmma_n*n_warps*n_buffers*n_stages_per_buffer\n",
    "work = M*N\n",
    "n_blocks = work//work_per_block\n",
    "\n",
    "n_registers_per_block = ((wmma_m*wmma_k)//2 + (wmma_k*wmma_n)//2  + wmma_n*wmma_m)*n_warps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c44e59bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_registers_per_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de4a4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tiled = np.arange(M*K//(wmma_m*wmma_n)).reshape(M//wmma_m, K//wmma_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70bf2d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ...,   253,   254,   255],\n",
       "       [  256,   257,   258, ...,   509,   510,   511],\n",
       "       [  512,   513,   514, ...,   765,   766,   767],\n",
       "       ...,\n",
       "       [64768, 64769, 64770, ..., 65021, 65022, 65023],\n",
       "       [65024, 65025, 65026, ..., 65277, 65278, 65279],\n",
       "       [65280, 65281, 65282, ..., 65533, 65534, 65535]], shape=(256, 256))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5895b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_wmma_units, B_wmma_units, C_wmma_units = np.empty((256,256)), np.empty((256,256)), np.empty((256,256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d95b7563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 512 16\n"
     ]
    }
   ],
   "source": [
    "N_warps_per_block = 32 \n",
    "N_c_warp_units = 256*256 \n",
    "N_sms = 170 \n",
    "N_stages = 512 \n",
    "work_per_block = N_stages*N_warps_per_block\n",
    "n_blocks = N_c_warp_units//work_per_block\n",
    "while n_blocks < 170: \n",
    "\n",
    "  work_per_block = N_stages*N_warps_per_block\n",
    "  n_blocks = N_c_warp_units//work_per_block\n",
    "  if N_stages == 16: \n",
    "    print(n_blocks, work_per_block, N_stages)\n",
    "  N_stages -= 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab51168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_per_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c10e40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbba0515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9550baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(32*16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b764556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65280\n"
     ]
    }
   ],
   "source": [
    "print(170*384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7867318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65536\n"
     ]
    }
   ],
   "source": [
    "print(256*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7cd29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smem_dyn_kb = 99\n",
    "# Use 1024 for KiB to Bytes conversion\n",
    "smem_total_bytes = smem_dyn_kb * 1024  \n",
    "# 99 * 1024 = 101,376 bytes\n",
    "\n",
    "# bf16 is 2 bytes\n",
    "n_max_bf16s_per_sm = smem_total_bytes // 2 \n",
    "# 101,376 // 2 = 50,688 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "218fb007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50688"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_max_bf16s_per_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e045b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smem_n_elements(BM,BN,BK): \n",
    "  return 16*16*(BM*BK + BK*BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa79b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = calculate_smem_n_elements(8,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8430b4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc5a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
