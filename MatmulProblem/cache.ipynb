{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f7c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block Size: 64 bytes\n",
      "Offset Bits: 6\n",
      "Offset Mask: 0b111111\n",
      "Tag Mask:    0b11111111111111111111111111000000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "class fully_associative_cache:\n",
    "  def __init__(self, mem_addr_width, cache_block_size, N_cache_blocks): \n",
    "    self.w = mem_addr_width      # e.g., 32 or 64 bits\n",
    "    self.b = cache_block_size    # e.g., 64 bytes\n",
    "    self.N_b = N_cache_blocks\n",
    "    \n",
    "    # 1. Calculate how many bits represent the offset\n",
    "    # If block size is 64, offset_bits = 6\n",
    "    self.offset_bits = int(math.log2(self.b))\n",
    "    \n",
    "    # 2. Create the masks\n",
    "    self.offset_mask = (1 << self.offset_bits) - 1\n",
    "    self.tag_mask = ((1 << self.w) - 1) ^ self.offset_mask\n",
    "    \n",
    "    print(f\"Block Size: {self.b} bytes\")\n",
    "    print(f\"Offset Bits: {self.offset_bits}\")\n",
    "    print(f\"Offset Mask: {bin(self.offset_mask)}\")\n",
    "    print(f\"Tag Mask:    {bin(self.tag_mask)}\")\n",
    "\n",
    "# Example Usage\n",
    "c = fully_associative_cache(32, 64, 128)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba67844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorCache Init: 4 Sets x 2 Ways x 64 Bytes\n",
      "Geometry: [ Tag: 24 | Index: 2 | Offset: 6 ]\n",
      "('MISS', np.uint8(170))\n",
      "('MISS', np.uint8(170))\n",
      "('MISS', np.uint8(170))\n",
      "('HIT', np.uint8(170))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class TensorCache:\n",
    "    def __init__(self, addr_width, block_size, num_sets, associativity):\n",
    "        self.W = addr_width\n",
    "        self.B = block_size      # Block Size (bytes)\n",
    "        self.S = num_sets        # Number of Sets (Rows)\n",
    "        self.K = associativity   # Ways (Columns)\n",
    "\n",
    "        # --- 1. Geometry & Addressing ---\n",
    "        self.offset_bits = int(math.log2(self.B))\n",
    "        self.index_bits  = int(math.log2(self.S))\n",
    "        self.tag_bits    = self.W - self.index_bits - self.offset_bits\n",
    "\n",
    "        # Bitmasks\n",
    "        self.offset_mask = (1 << self.offset_bits) - 1\n",
    "        self.index_mask  = ((1 << self.index_bits) - 1) << self.offset_bits\n",
    "\n",
    "        # --- 2. The Tensors (State) ---\n",
    "        # Shape: (S, K) -> (Sets, Ways)\n",
    "        # We use -1 for invalid tags initially\n",
    "        self.tags = np.full((self.S, self.K), -1, dtype=np.int64)\n",
    "        self.valid = np.zeros((self.S, self.K), dtype=bool)\n",
    "        \n",
    "        # LRU Tensor: (S, K). \n",
    "        # Logic: Higher number = More recently used. 0 = Oldest/Empty.\n",
    "        self.lru_counters = np.zeros((self.S, self.K), dtype=np.int64)\n",
    "        self.global_timer = 0 # Monotonic clock for LRU\n",
    "\n",
    "        # Data Tensor: (S, K, B)\n",
    "        self.data = np.zeros((self.S, self.K, self.B), dtype=np.uint8)\n",
    "\n",
    "        print(f\"TensorCache Init: {self.S} Sets x {self.K} Ways x {self.B} Bytes\")\n",
    "        print(f\"Geometry: [ Tag: {self.tag_bits} | Index: {self.index_bits} | Offset: {self.offset_bits} ]\")\n",
    "\n",
    "    def _split_addr(self, addr):\n",
    "        offset = addr & self.offset_mask\n",
    "        index  = (addr & self.index_mask) >> self.offset_bits\n",
    "        tag    = addr >> (self.index_bits + self.offset_bits)\n",
    "        return tag, index, offset\n",
    "\n",
    "    def lookup(self, addr):\n",
    "        self.global_timer += 1\n",
    "        tag_in, idx_in, off_in = self._split_addr(addr)\n",
    "        \n",
    "        # --- 1. Slice (Select the Set) ---\n",
    "        # We grab the specific row for this Set Index.\n",
    "        # Hardware: This is the decoder enabling one specific wordline.\n",
    "        set_tags = self.tags[idx_in, :]      # Shape: (K,)\n",
    "        set_valid = self.valid[idx_in, :]    # Shape: (K,)\n",
    "\n",
    "        # --- 2. Search (Broadcast & Contract) ---\n",
    "        # Compare Input Tag against ALL K ways in parallel\n",
    "        # hit_vector becomes a boolean array e.g., [False, True, False, False]\n",
    "        hit_vector = (set_tags == tag_in) & (set_valid)\n",
    "\n",
    "        if np.any(hit_vector):\n",
    "            # === HIT ===\n",
    "            # Find which way hit (e.g., Way 1)\n",
    "            way_idx = np.where(hit_vector)[0][0]\n",
    "            \n",
    "            # Update LRU\n",
    "            self.lru_counters[idx_in, way_idx] = self.global_timer\n",
    "            \n",
    "            # Retrieve Data (Slice the Data Tensor)\n",
    "            # data shape: (S, K, B) -> scalar byte\n",
    "            val = self.data[idx_in, way_idx, off_in]\n",
    "            return \"HIT\", val\n",
    "        \n",
    "        else:\n",
    "            # === MISS ===\n",
    "            return \"MISS\", self._handle_miss(tag_in, idx_in, off_in)\n",
    "\n",
    "    def _handle_miss(self, tag, idx, offset):\n",
    "        # 1. Find Victim (LRU Eviction)\n",
    "        # Look at the counters for this specific set\n",
    "        # argmin gives us the index of the oldest (smallest) timer\n",
    "        victim_way = np.argmin(self.lru_counters[idx, :])\n",
    "\n",
    "        # 2. \"Fetch\" from memory (simulated)\n",
    "        # In a real engine, this is a GMEM load\n",
    "        new_data_block = np.full((self.B), 0xAA, dtype=np.uint8) # 0xAA dummy data\n",
    "\n",
    "        # 3. Update Tensors\n",
    "        self.tags[idx, victim_way]  = tag\n",
    "        self.valid[idx, victim_way] = True\n",
    "        self.lru_counters[idx, victim_way] = self.global_timer\n",
    "        self.data[idx, victim_way, :] = new_data_block\n",
    "\n",
    "        return new_data_block[offset]\n",
    "\n",
    "# --- Usage ---\n",
    "# 32-bit addr, 64B block, 4 Sets, 2 Ways\n",
    "cache = TensorCache(32, 64, 4, 2)\n",
    "\n",
    "# 1. Cold Miss\n",
    "print(cache.lookup(0x1000)) # Set 0, Way 0 filled\n",
    "\n",
    "# 2. Cold Miss (Same Set, Different Tag)\n",
    "print(cache.lookup(0x2000)) # Set 0, Way 1 filled\n",
    "\n",
    "# 3. Conflict Miss (Same Set, Cache Full -> Evict LRU (Way 0))\n",
    "print(cache.lookup(0x3000)) \n",
    "\n",
    "# 4. Hit (Back to 0x3000)\n",
    "print(cache.lookup(0x3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
