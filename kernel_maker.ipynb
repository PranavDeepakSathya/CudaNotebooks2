{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28109ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cutlass\n",
    "import cutlass.cute as cute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "710aeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.kernel \n",
    "def kernel(): \n",
    "  tidx, _, _ = cute.arch.thread_idx()\n",
    "  if tidx == 0:\n",
    "    cute.printf(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b897ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.jit\n",
    "def hello_world():\n",
    "    # Print hello world from host code\n",
    "    cute.printf(\"hello world\")\n",
    "\n",
    "    # Launch kernel\n",
    "    kernel().launch(\n",
    "        grid=(1, 1, 1),  # Single thread block\n",
    "        block=(32, 1, 1),  # One warp (32 threads) per thread block\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6453e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hello_world()...\n",
      "hello world\n",
      "Compiling...\n",
      "Hello World!\n",
      "Compiling with PTX/CUBIN dumped...\n",
      "Running compiled version...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "cutlass.cuda.initialize_cuda_context()\n",
    "\n",
    "# Method 1: Just-In-Time (JIT) compilation - compiles and runs the code immediately\n",
    "print(\"Running hello_world()...\")\n",
    "hello_world()\n",
    "\n",
    "# Method 2: Compile first (useful if you want to run the same code multiple times)\n",
    "print(\"Compiling...\")\n",
    "hello_world_compiled = cute.compile(hello_world)\n",
    "\n",
    "# Dump PTX/CUBIN files while compiling\n",
    "from cutlass.cute import KeepPTX, KeepCUBIN\n",
    "\n",
    "print(\"Compiling with PTX/CUBIN dumped...\")\n",
    "# Alternatively, compile with string based options like\n",
    "# cute.compile(hello_world, options=\"--keep-ptx --keep-cubin\") would also work.\n",
    "hello_world_compiled_ptx_on = cute.compile[KeepPTX, KeepCUBIN](hello_world)\n",
    "\n",
    "# Run the pre-compiled version\n",
    "print(\"Running compiled version...\")\n",
    "hello_world_compiled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73a568fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.jit\n",
    "def make_layout():\n",
    "  layout = cute.make_layout((3,4),stride=(1,3))\n",
    "  cute.printf(cute.coalesce(layout))\n",
    "  for i in range(cute.size(layout)):\n",
    "    cute.printf(layout(i)) \n",
    "    \n",
    "  return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb8e506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "L = make_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4909a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import cutlass\n",
    "import cutlass.cute as cute\n",
    "import cutlass.utils as utils\n",
    "import cutlass.torch as cutlass_torch\n",
    "import cutlass.pipeline as pipeline\n",
    "from cutlass.cute.nvgpu import cpasync, tcgen05\n",
    "import cutlass.utils.blackwell_helpers as sm100_utils\n",
    "from cutlass.cute.runtime import from_dlpack\n",
    "from cutlass.cute import KeepPTX, KeepCUBIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c1c769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_dtype = cutlass.Float16\n",
    "acc_dtype = cutlass.Float32\n",
    "mma_inst_shape_mnk = (128, 256, 16)\n",
    "mma_tiler_mnk = (128, 256, 64)\n",
    "threads_per_cta = 128\n",
    "\n",
    "# Pipeline stage configuration\n",
    "ab_stages = 4\n",
    "acc_stage = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5af055bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n, k = 8192, 8192, 8192\n",
    "\n",
    "# Make K-major tensors (torch tensors are row-major)\n",
    "def make_tensors(mn, k, dtype):\n",
    "    shape = (mn, k)\n",
    "    return (\n",
    "        torch.empty(*shape, dtype=torch.int32)\n",
    "        .random_(-2, 2)\n",
    "        .to(dtype=dtype, device=\"cuda\")\n",
    "    )\n",
    "\n",
    "a = make_tensors(m, k, cutlass_torch.dtype(io_dtype))\n",
    "b = make_tensors(n, k, cutlass_torch.dtype(io_dtype))\n",
    "c = make_tensors(m, n, cutlass_torch.dtype(io_dtype))\n",
    "a_tensor = (\n",
    "    from_dlpack(a)\n",
    "    .mark_layout_dynamic(leading_dim=1)\n",
    ")\n",
    "b_tensor = (\n",
    "    from_dlpack(b)\n",
    "    .mark_layout_dynamic(leading_dim=1)\n",
    ")\n",
    "c_tensor = (\n",
    "    from_dlpack(c)\n",
    "    .mark_layout_dynamic(leading_dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd052ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.struct\n",
    "class SharedStorage:\n",
    "    ab_mbar_ptr: cute.struct.MemRange[cutlass.Int64, ab_stages * 2]\n",
    "    acc_mbar_ptr: cute.struct.MemRange[cutlass.Int64, acc_stage * 2]\n",
    "    tmem_holding_buf: cutlass.Int32\n",
    "\n",
    "\n",
    "@cute.kernel\n",
    "def kernel(\n",
    "    tiled_mma: cute.TiledMma,\n",
    "    tma_atom_a: cute.CopyAtom,\n",
    "    mA_mkl: cute.Tensor,\n",
    "    tma_atom_b: cute.CopyAtom,\n",
    "    mB_nkl: cute.Tensor,\n",
    "    mC_mnl: cute.Tensor,\n",
    "    a_smem_layout: cute.ComposedLayout,\n",
    "    b_smem_layout: cute.ComposedLayout,\n",
    "):\n",
    "    #\n",
    "    # 1. Prepare args\n",
    "    #\n",
    "\n",
    "    # Current thread/warp/block coordinates\n",
    "    tidx, _, _ = cute.arch.thread_idx()\n",
    "    warp_idx = cute.arch.warp_idx()\n",
    "    warp_idx = cute.arch.make_warp_uniform(warp_idx)\n",
    "    bidx, bidy, _ = cute.arch.block_idx()\n",
    "    mma_coord_mnk = (bidx, bidy, None)\n",
    "\n",
    "    # Allocate SMEM\n",
    "    smem = cutlass.utils.SmemAllocator()\n",
    "    storage = smem.allocate(SharedStorage)\n",
    "    sA = smem.allocate_tensor(\n",
    "        element_type=io_dtype,\n",
    "        layout=a_smem_layout.outer,\n",
    "        byte_alignment=128,\n",
    "        swizzle=a_smem_layout.inner,\n",
    "    )\n",
    "    sB = smem.allocate_tensor(\n",
    "        element_type=io_dtype,\n",
    "        layout=b_smem_layout.outer,\n",
    "        byte_alignment=128,\n",
    "        swizzle=b_smem_layout.inner,\n",
    "    )\n",
    "\n",
    "    # Allocate all TMEM columns\n",
    "    tmem_alloc_barrier = pipeline.NamedBarrier(\n",
    "        barrier_id=1,\n",
    "        num_threads=threads_per_cta,\n",
    "    )\n",
    "    tmem = utils.TmemAllocator(\n",
    "        storage.tmem_holding_buf,\n",
    "        barrier_for_retrieve=tmem_alloc_barrier,\n",
    "    )\n",
    "    num_tmem_cols = 512\n",
    "    tmem.allocate(num_tmem_cols)\n",
    "\n",
    "    # Prefetch tma descriptor\n",
    "    if warp_idx == 0:\n",
    "        cpasync.prefetch_descriptor(tma_atom_a)\n",
    "        cpasync.prefetch_descriptor(tma_atom_b)\n",
    "\n",
    "    # Pipeline configuration\n",
    "    num_tma_copy_bytes = cute.size_in_bytes(\n",
    "        io_dtype, cute.select(a_smem_layout, mode=[0, 1, 2])\n",
    "    ) + cute.size_in_bytes(io_dtype, cute.select(b_smem_layout, mode=[0, 1, 2]))\n",
    "    ab_producer, ab_consumer = pipeline.PipelineTmaUmma.create(\n",
    "        num_stages=ab_stages,\n",
    "        producer_group=pipeline.CooperativeGroup(pipeline.Agent.Thread),\n",
    "        consumer_group=pipeline.CooperativeGroup(pipeline.Agent.Thread),\n",
    "        tx_count=num_tma_copy_bytes,\n",
    "        barrier_storage=storage.ab_mbar_ptr.data_ptr(),\n",
    "    ).make_participants()\n",
    "    acc_producer, acc_consumer = pipeline.PipelineUmmaAsync.create(\n",
    "        num_stages=acc_stage,\n",
    "        producer_group=pipeline.CooperativeGroup(pipeline.Agent.Thread),\n",
    "        consumer_group=pipeline.CooperativeGroup(\n",
    "            pipeline.Agent.Thread, threads_per_cta\n",
    "        ),\n",
    "        barrier_storage=storage.acc_mbar_ptr.data_ptr(),\n",
    "    ).make_participants()\n",
    "\n",
    "    # Partition tensors for MMA and make fragments\n",
    "    # (bM, bK, RestK)\n",
    "    gA = cute.local_tile(mA_mkl, mma_tiler_mnk, mma_coord_mnk, proj=(1, None, 1))\n",
    "    # (bN, bK, RestK)\n",
    "    gB = cute.local_tile(mB_nkl, mma_tiler_mnk, mma_coord_mnk, proj=(None, 1, 1))\n",
    "    # (bM, bN)\n",
    "    gC = cute.local_tile(mC_mnl, mma_tiler_mnk, mma_coord_mnk, proj=(1, 1, None))\n",
    "    thr_mma = tiled_mma.get_slice(0)\n",
    "    # (MMA, MMA_M, MMA_K)\n",
    "    tCgA = thr_mma.partition_A(gA)\n",
    "    # (MMA, MMA_N, MMA_K)\n",
    "    tCgB = thr_mma.partition_B(gB)\n",
    "    # (MMA, MMA_M, MMA_N)\n",
    "    tCgC = thr_mma.partition_C(gC)\n",
    "    # (MMA, MMA_M, MMA_K)\n",
    "    tCrA = tiled_mma.make_fragment_A(sA)\n",
    "    # (MMA, MMA_N, MMA_K)\n",
    "    tCrB = tiled_mma.make_fragment_B(sB)\n",
    "    # (MMA, MMA_M, MMA_N)\n",
    "    acc_shape = tiled_mma.partition_shape_C(mma_tiler_mnk[:2])\n",
    "    # (MMA, MMA_M, MMA_N)\n",
    "    tCtAcc = tiled_mma.make_fragment_C(acc_shape)\n",
    "    # Partition tensors for TMA; This requires the tensors partitioned for MMA\n",
    "    tAsA, tAgA = cute.nvgpu.cpasync.tma_partition(\n",
    "        tma_atom_a,\n",
    "        0,\n",
    "        cute.make_layout(1),\n",
    "        cute.group_modes(sA, 0, 3),\n",
    "        cute.group_modes(tCgA, 0, 3),\n",
    "    )\n",
    "    tBsB, tBgB = cute.nvgpu.cpasync.tma_partition(\n",
    "        tma_atom_b,\n",
    "        0,\n",
    "        cute.make_layout(1),\n",
    "        cute.group_modes(sB, 0, 3),\n",
    "        cute.group_modes(tCgB, 0, 3),\n",
    "    )\n",
    "\n",
    "    # CTA-wide sync before retrieving the pointer to the start of the allocated TMEM\n",
    "    # Only warp 0 does the allocation so we need to sync before retrieving the TMEM start address\n",
    "    tmem.wait_for_alloc()\n",
    "    tmem_ptr = tmem.retrieve_ptr(acc_dtype)\n",
    "    # Swap the pointer in tCtAcc\n",
    "    tCtAcc = cute.make_tensor(tmem_ptr, tCtAcc.layout)\n",
    "\n",
    "    subtile_cnt = 4\n",
    "    # (EpiTile)\n",
    "    epi_tiler = (\n",
    "        (cute.size(tCtAcc, mode=[0, 0]), cute.size(tCtAcc, mode=[0, 1]) // subtile_cnt),\n",
    "    )\n",
    "    # (EpiTile, NumTiles)\n",
    "    tCtAcc_epi = cute.zipped_divide(tCtAcc, epi_tiler)\n",
    "    # (EpiTile, NumTiles)\n",
    "    gC_epi = cute.zipped_divide(tCgC, epi_tiler)\n",
    "\n",
    "    # Every thread loads 32x128 bits\n",
    "    tmem_atom = cute.make_copy_atom(\n",
    "        tcgen05.Ld32x32bOp(tcgen05.Repetition.x64),\n",
    "        cutlass.Float32,\n",
    "    )\n",
    "    tmem_tiled_copy = tcgen05.make_tmem_copy(tmem_atom, tCtAcc_epi[None, 0])\n",
    "    tmem_thr_copy = tmem_tiled_copy.get_slice(tidx)\n",
    "\n",
    "    # (TmemCpy,NumTmemCpy,NumTiles)\n",
    "    tDtC = tmem_thr_copy.partition_S(tCtAcc_epi)\n",
    "    # (TmemCpy,NumTmemCpy,NumTiles)\n",
    "    tDgC = tmem_thr_copy.partition_D(gC_epi)\n",
    "\n",
    "    # (TmemCpy,NumTmemCpy)\n",
    "    tCrAcc = cute.make_rmem_tensor(tDgC[None, None, 0].shape, acc_dtype)\n",
    "    # (TmemCpy,NumTmemCpy)\n",
    "    tCrC = cute.make_rmem_tensor(tDgC[None, None, 0].shape, io_dtype)\n",
    "\n",
    "    #\n",
    "    # 2. Main loop\n",
    "    #\n",
    "    num_k_tiles = cute.size(gA, mode=[2])\n",
    "    if warp_idx == 0:\n",
    "        # Wait for a empty accumulator buffer\n",
    "        acc_empty = acc_producer.acquire_and_advance()\n",
    "        for k_tile_idx in cutlass.range(num_k_tiles):\n",
    "            # Issue TMA loads\n",
    "            ab_empty = ab_producer.acquire_and_advance()\n",
    "            cute.copy(\n",
    "                tma_atom_a,\n",
    "                tAgA[(None, ab_empty.count)],\n",
    "                tAsA[(None, ab_empty.index)],\n",
    "                tma_bar_ptr=ab_empty.barrier,\n",
    "            )\n",
    "            cute.copy(\n",
    "                tma_atom_b,\n",
    "                tBgB[(None, ab_empty.count)],\n",
    "                tBsB[(None, ab_empty.index)],\n",
    "                tma_bar_ptr=ab_empty.barrier,\n",
    "            )\n",
    "\n",
    "            # Execute one K-block worth of MMA instructions\n",
    "            ab_full = ab_consumer.wait_and_advance()\n",
    "            num_k_blocks = cute.size(tCrA, mode=[2])\n",
    "            for k_block_idx in cutlass.range_constexpr(num_k_blocks):\n",
    "                k_block_coord = (None, None, k_block_idx, ab_full.index)\n",
    "                cute.gemm(\n",
    "                    tiled_mma,\n",
    "                    tCtAcc,\n",
    "                    tCrA[k_block_coord],\n",
    "                    tCrB[k_block_coord],\n",
    "                    tCtAcc,\n",
    "                )\n",
    "                tiled_mma.set(tcgen05.Field.ACCUMULATE, True)\n",
    "\n",
    "            # Signal that the A/B buffers have been consumed and are ready for the next load\n",
    "            ab_full.release()\n",
    "\n",
    "        # Signal that the accumulator is fully computed\n",
    "        acc_empty.commit()\n",
    "\n",
    "    #\n",
    "    # 3. Epilogue\n",
    "    #\n",
    "\n",
    "    # Release TMEM allocation lock\n",
    "    tmem.relinquish_alloc_permit()\n",
    "\n",
    "    # Wait for the accumulator buffer to be full\n",
    "    acc_full = acc_consumer.wait_and_advance()\n",
    "\n",
    "    # TMEM -> RMEM -> GEMM\n",
    "    # Sub-tiling for better instruction-level parallelism\n",
    "    for i in cutlass.range(cute.size(tDtC, mode=[2])):\n",
    "        cute.copy(tmem_tiled_copy, tDtC[None, None, i], tCrAcc)\n",
    "        tCrC.store(tCrAcc.load().to(io_dtype))\n",
    "        cute.autovec_copy(tCrC, tDgC[None, None, i])\n",
    "    acc_full.release()\n",
    "\n",
    "    # Deallocate TMEM\n",
    "    pipeline.sync(barrier_id=1)\n",
    "    tmem.free(tmem_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "780a7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.jit\n",
    "def host_function(\n",
    "    a: cute.Tensor,\n",
    "    b: cute.Tensor,\n",
    "    c: cute.Tensor,\n",
    "    kernel: cutlass.Constexpr,\n",
    "):\n",
    "    # Construct tiled MMA\n",
    "    op = tcgen05.MmaF16BF16Op(\n",
    "        io_dtype,\n",
    "        acc_dtype,\n",
    "        mma_inst_shape_mnk,\n",
    "        tcgen05.CtaGroup.ONE,\n",
    "        tcgen05.OperandSource.SMEM,\n",
    "        tcgen05.OperandMajorMode.K,\n",
    "        tcgen05.OperandMajorMode.K,\n",
    "    )\n",
    "    tiled_mma = cute.make_tiled_mma(op)\n",
    "\n",
    "    # Construct SMEM layouts for A and B\n",
    "    a_smem_layout = sm100_utils.make_smem_layout_a(\n",
    "        tiled_mma,\n",
    "        mma_tiler_mnk,\n",
    "        a.element_type,\n",
    "        ab_stages,\n",
    "    )\n",
    "    b_smem_layout = sm100_utils.make_smem_layout_b(\n",
    "        tiled_mma,\n",
    "        mma_tiler_mnk,\n",
    "        b.element_type,\n",
    "        ab_stages,\n",
    "    )\n",
    "    a_smem_layout_one_stage = cute.select(a_smem_layout, mode=[0, 1, 2])\n",
    "    b_smem_layout_one_stage = cute.select(b_smem_layout, mode=[0, 1, 2])\n",
    "\n",
    "    # Construct TMA load atoms\n",
    "    op = cute.nvgpu.cpasync.CopyBulkTensorTileG2SOp(tcgen05.CtaGroup.ONE)\n",
    "    a_tma_atom, a_tma_tensor = cute.nvgpu.make_tiled_tma_atom_A(\n",
    "        op,\n",
    "        a,\n",
    "        a_smem_layout_one_stage,\n",
    "        mma_tiler_mnk,\n",
    "        tiled_mma,\n",
    "    )\n",
    "    b_tma_atom, b_tma_tensor = cute.nvgpu.make_tiled_tma_atom_B(\n",
    "        op,\n",
    "        b,\n",
    "        b_smem_layout_one_stage,\n",
    "        mma_tiler_mnk,\n",
    "        tiled_mma,\n",
    "    )\n",
    "\n",
    "    # Launch the kernel\n",
    "    grid_shape = cute.ceil_div((*c.layout.shape, 1), mma_tiler_mnk[:2])\n",
    "    kernel(\n",
    "        tiled_mma,\n",
    "        a_tma_atom,\n",
    "        a_tma_tensor,\n",
    "        b_tma_atom,\n",
    "        b_tma_tensor,\n",
    "        c,\n",
    "        a_smem_layout,\n",
    "        b_smem_layout,\n",
    "    ).launch(\n",
    "        grid=grid_shape,\n",
    "        block=(threads_per_cta, 1, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4a9b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_kernel = cute.compile[KeepPTX, KeepCUBIN](host_function, a_tensor, b_tensor, c_tensor, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06d5303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cute.kernel\n",
    "def kernel_with_prefetch(\n",
    "    tiled_mma: cute.TiledMma,\n",
    "    tma_atom_a: cute.CopyAtom,\n",
    "    mA_mkl: cute.Tensor,\n",
    "    tma_atom_b: cute.CopyAtom,\n",
    "    mB_nkl: cute.Tensor,\n",
    "    mC_mnl: cute.Tensor,\n",
    "    a_smem_layout: cute.ComposedLayout,\n",
    "    b_smem_layout: cute.ComposedLayout,\n",
    "):\n",
    "    #\n",
    "    # 1. Prepare args\n",
    "    #\n",
    "\n",
    "    # Current thread/warp/block coordinates\n",
    "    tidx, _, _ = cute.arch.thread_idx()\n",
    "    warp_idx = cute.arch.warp_idx()\n",
    "    warp_idx = cute.arch.make_warp_uniform(warp_idx)\n",
    "    bidx, bidy, _ = cute.arch.block_idx()\n",
    "    mma_coord_mnk = (bidx, bidy, None)\n",
    "\n",
    "    # Allocate SMEM\n",
    "    smem = cutlass.utils.SmemAllocator()\n",
    "    storage = smem.allocate(SharedStorage)\n",
    "    sA = smem.allocate_tensor(\n",
    "        element_type=io_dtype,\n",
    "        layout=a_smem_layout.outer,\n",
    "        byte_alignment=128,\n",
    "        swizzle=a_smem_layout.inner,\n",
    "    )\n",
    "    sB = smem.allocate_tensor(\n",
    "        element_type=io_dtype,\n",
    "        layout=b_smem_layout.outer,\n",
    "        byte_alignment=128,\n",
    "        swizzle=b_smem_layout.inner,\n",
    "    )\n",
    "\n",
    "    # Allocate all TMEM columns\n",
    "    tmem_alloc_barrier = pipeline.NamedBarrier(\n",
    "        barrier_id=1,\n",
    "        num_threads=threads_per_cta,\n",
    "    )\n",
    "    tmem = utils.TmemAllocator(\n",
    "        storage.tmem_holding_buf,\n",
    "        barrier_for_retrieve=tmem_alloc_barrier,\n",
    "    )\n",
    "    num_tmem_cols = 512\n",
    "    tmem.allocate(num_tmem_cols)\n",
    "\n",
    "    # Prefetch tma descriptor\n",
    "    if warp_idx == 0:\n",
    "        cpasync.prefetch_descriptor(tma_atom_a)\n",
    "        cpasync.prefetch_descriptor(tma_atom_b)\n",
    "\n",
    "    # Pipeline configuration\n",
    "    num_tma_copy_bytes = cute.size_in_bytes(\n",
    "        io_dtype, cute.select(a_smem_layout, mode=[0, 1, 2])\n",
    "    ) + cute.size_in_bytes(io_dtype, cute.select(b_smem_layout, mode=[0, 1, 2]))\n",
    "    ab_producer, ab_consumer = pipeline.PipelineTmaUmma.create(\n",
    "        num_stages=ab_stages,\n",
    "        producer_group=pipeline.CooperativeGroup(pipeline.Agent.Thread),\n",
    "        consumer_group=pipeline.CooperativeGroup(pipeline.Agent.Thread),\n",
    "        tx_count=num_tma_copy_bytes,\n",
    "        barrier_storage=storage.ab_mbar_ptr.data_ptr(),\n",
    "    ).make_participants()\n",
    "    acc_producer, acc_consumer = pipeline.PipelineUmmaAsync.create(\n",
    "        num_stages=acc_stage,\n",
    "        producer_group=pipeline.CooperativeGroup(pipeline.Agent.Thread),\n",
    "        consumer_group=pipeline.CooperativeGroup(\n",
    "            pipeline.Agent.Thread, threads_per_cta\n",
    "        ),\n",
    "        barrier_storage=storage.acc_mbar_ptr.data_ptr(),\n",
    "    ).make_participants()\n",
    "\n",
    "    # Partition tensors for MMA and make fragments\n",
    "    # (bM, bK, RestK)\n",
    "    gA = cute.local_tile(mA_mkl, mma_tiler_mnk, mma_coord_mnk, proj=(1, None, 1))\n",
    "    # (bN, bK, RestK)\n",
    "    gB = cute.local_tile(mB_nkl, mma_tiler_mnk, mma_coord_mnk, proj=(None, 1, 1))\n",
    "    # (bM, bN)\n",
    "    gC = cute.local_tile(mC_mnl, mma_tiler_mnk, mma_coord_mnk, proj=(1, 1, None))\n",
    "    thr_mma = tiled_mma.get_slice(0)\n",
    "    # (MMA, MMA_M, MMA_K)\n",
    "    tCgA = thr_mma.partition_A(gA)\n",
    "    # (MMA, MMA_N, MMA_K)\n",
    "    tCgB = thr_mma.partition_B(gB)\n",
    "    # (MMA, MMA_M, MMA_N)\n",
    "    tCgC = thr_mma.partition_C(gC)\n",
    "    # (MMA, MMA_M, MMA_K)\n",
    "    tCrA = tiled_mma.make_fragment_A(sA)\n",
    "    # (MMA, MMA_N, MMA_K)\n",
    "    tCrB = tiled_mma.make_fragment_B(sB)\n",
    "    # (MMA, MMA_M, MMA_N)\n",
    "    acc_shape = tiled_mma.partition_shape_C(mma_tiler_mnk[:2])\n",
    "    # (MMA, MMA_M, MMA_N)\n",
    "    tCtAcc = tiled_mma.make_fragment_C(acc_shape)\n",
    "    # Partition tensors for TMA; This requires the tensors partitioned for MMA\n",
    "    tAsA, tAgA = cute.nvgpu.cpasync.tma_partition(\n",
    "        tma_atom_a,\n",
    "        0,\n",
    "        cute.make_layout(1),\n",
    "        cute.group_modes(sA, 0, 3),\n",
    "        cute.group_modes(tCgA, 0, 3),\n",
    "    )\n",
    "    tBsB, tBgB = cute.nvgpu.cpasync.tma_partition(\n",
    "        tma_atom_b,\n",
    "        0,\n",
    "        cute.make_layout(1),\n",
    "        cute.group_modes(sB, 0, 3),\n",
    "        cute.group_modes(tCgB, 0, 3),\n",
    "    )\n",
    "\n",
    "    # CTA-wide sync before retrieving the pointer to the start of the allocated TMEM\n",
    "    # Only warp 0 does the allocation so we need to sync before retrieving the TMEM start address\n",
    "    tmem.wait_for_alloc()\n",
    "    tmem_ptr = tmem.retrieve_ptr(acc_dtype)\n",
    "    # Swap the pointer in tCtAcc\n",
    "    tCtAcc = cute.make_tensor(tmem_ptr, tCtAcc.layout)\n",
    "\n",
    "    subtile_cnt = 4\n",
    "    # (EpiTile)\n",
    "    epi_tiler = (\n",
    "        (cute.size(tCtAcc, mode=[0, 0]), cute.size(tCtAcc, mode=[0, 1]) // subtile_cnt),\n",
    "    )\n",
    "    # (EpiTile, NumTiles)\n",
    "    tCtAcc_epi = cute.zipped_divide(tCtAcc, epi_tiler)\n",
    "    # (EpiTile, NumTiles)\n",
    "    gC_epi = cute.zipped_divide(tCgC, epi_tiler)\n",
    "\n",
    "    # Every thread loads 32x128 bits\n",
    "    tmem_atom = cute.make_copy_atom(\n",
    "        tcgen05.Ld32x32bOp(tcgen05.Repetition.x64),\n",
    "        cutlass.Float32,\n",
    "    )\n",
    "    tmem_tiled_copy = tcgen05.make_tmem_copy(tmem_atom, tCtAcc_epi[None, 0])\n",
    "    tmem_thr_copy = tmem_tiled_copy.get_slice(tidx)\n",
    "\n",
    "    # (TmemCpy,NumTmemCpy,NumTiles)\n",
    "    tDtC = tmem_thr_copy.partition_S(tCtAcc_epi)\n",
    "    # (TmemCpy,NumTmemCpy,NumTiles)\n",
    "    tDgC = tmem_thr_copy.partition_D(gC_epi)\n",
    "\n",
    "    # (TmemCpy,NumTmemCpy)\n",
    "    tCrAcc = cute.make_rmem_tensor(tDgC[None, None, 0].shape, acc_dtype)\n",
    "    # (TmemCpy,NumTmemCpy)\n",
    "    tCrC = cute.make_rmem_tensor(tDgC[None, None, 0].shape, io_dtype)\n",
    "\n",
    "    #\n",
    "    # 2. Main loop\n",
    "    #\n",
    "    num_k_tiles = cute.size(gA, mode=[2])\n",
    "    if warp_idx == 0:\n",
    "        # Wait for a empty accumulator buffer\n",
    "        acc_empty = acc_producer.acquire_and_advance()\n",
    "        for k_tile_idx in cutlass.range(num_k_tiles, prefetch_stages=ab_stages - 2):\n",
    "            # Issue TMA loads\n",
    "            ab_empty = ab_producer.acquire_and_advance()\n",
    "            cute.copy(\n",
    "                tma_atom_a,\n",
    "                tAgA[(None, ab_empty.count)],\n",
    "                tAsA[(None, ab_empty.index)],\n",
    "                tma_bar_ptr=ab_empty.barrier,\n",
    "            )\n",
    "            cute.copy(\n",
    "                tma_atom_b,\n",
    "                tBgB[(None, ab_empty.count)],\n",
    "                tBsB[(None, ab_empty.index)],\n",
    "                tma_bar_ptr=ab_empty.barrier,\n",
    "            )\n",
    "\n",
    "            # Execute one K-block worth of MMA instructions\n",
    "            ab_full = ab_consumer.wait_and_advance()\n",
    "            num_k_blocks = cute.size(tCrA, mode=[2])\n",
    "            for k_block_idx in cutlass.range_constexpr(num_k_blocks):\n",
    "                k_block_coord = (None, None, k_block_idx, ab_full.index)\n",
    "                cute.gemm(\n",
    "                    tiled_mma,\n",
    "                    tCtAcc,\n",
    "                    tCrA[k_block_coord],\n",
    "                    tCrB[k_block_coord],\n",
    "                    tCtAcc,\n",
    "                )\n",
    "                tiled_mma.set(tcgen05.Field.ACCUMULATE, True)\n",
    "\n",
    "            # Signal that the A/B buffers have been consumed and are ready for the next load\n",
    "            ab_full.release()\n",
    "\n",
    "        # Signal that the accumulator is fully computed\n",
    "        acc_empty.commit()\n",
    "\n",
    "    #\n",
    "    # 3. Epilogue\n",
    "    #\n",
    "\n",
    "    # Release TMEM allocation lock\n",
    "    tmem.relinquish_alloc_permit()\n",
    "\n",
    "    # Wait for the accumulator buffer to be full\n",
    "    acc_full = acc_consumer.wait_and_advance()\n",
    "\n",
    "    # TMEM -> RMEM -> GEMM\n",
    "    # Sub-tiling for better instruction-level parallelism\n",
    "    for i in cutlass.range(cute.size(tDtC, mode=[2])):\n",
    "        cute.copy(tmem_tiled_copy, tDtC[None, None, i], tCrAcc)\n",
    "        tCrC.store(tCrAcc.load().to(io_dtype))\n",
    "        cute.autovec_copy(tCrC, tDgC[None, None, i])\n",
    "    acc_full.release()\n",
    "\n",
    "    # Deallocate TMEM\n",
    "    pipeline.sync(barrier_id=1)\n",
    "    tmem.free(tmem_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4363a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefetch_kernel = cute.compile[KeepPTX,KeepCUBIN](host_function, a_tensor, b_tensor, c_tensor, kernel_with_prefetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7557ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tensor_ = (\n",
    "    from_dlpack(a, assumed_align=32)\n",
    "    .mark_layout_dynamic(leading_dim=1)\n",
    "    .mark_compact_shape_dynamic(mode=1, divisibility=k)\n",
    ")\n",
    "b_tensor_ = (\n",
    "    from_dlpack(b, assumed_align=32)\n",
    "    .mark_layout_dynamic(leading_dim=1)\n",
    "    .mark_compact_shape_dynamic(mode=1, divisibility=k)\n",
    ")\n",
    "c_tensor_ = (\n",
    "    from_dlpack(c, assumed_align=32)\n",
    "    .mark_layout_dynamic(leading_dim=1)\n",
    "    .mark_compact_shape_dynamic(mode=1, divisibility=n)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the kernel for the specific input types\n",
    "vectorized_kernel = cute.compile[KeepPTX, KeepCUBIN](host_function, a_tensor_, b_tensor_, c_tensor_, kernel_with_prefetch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecf9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
