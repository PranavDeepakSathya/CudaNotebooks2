//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36006120
// Cuda compilation tools, release 12.9, V12.9.83
// Based on NVVM 20.0.0
//

.version 8.8
.target sm_100a
.address_size 64

	// .globl	kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0
.extern .shared .align 1024 .b8 __dynamic_shmem__0[];

.visible .entry kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0(
	.param .align 1 .b8 kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_0[3],
	.param .align 64 .b8 kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_1[128],
	.param .align 4 .b8 kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_2[8],
	.param .align 64 .b8 kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_3[128],
	.param .align 4 .b8 kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_4[8],
	.param .align 8 .b8 kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_5[24]
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<45>;
	.reg .b16 	%rs<71>;
	.reg .b32 	%r<219>;
	.reg .f32 	%f<65>;
	.reg .b64 	%rd<41>;

	ld.param.u8 	%rs1, [kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_0+2];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16 	%p12, %rs2, 1;
	ld.param.u8 	%rs3, [kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_0+1];
	and.b16  	%rs4, %rs3, 1;
	setp.eq.b16 	%p11, %rs4, 1;
	ld.param.u8 	%rs5, [kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_0];
	and.b16  	%rs6, %rs5, 1;
	setp.eq.b16 	%p44, %rs6, 1;
	ld.param.u64 	%rd9, [kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_5+16];
	ld.param.u64 	%rd8, [kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_5];
	ld.param.u32 	%r44, [kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_2+4];
	mov.b64 	%rd7, kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_1;
	mov.b64 	%rd10, kernel_cutlass_kernel_TiledMMA_ThrLayoutVMNK11110000_PermutationMNK____MMAAtom_ThrID10_ShapeMNK12825616_TVLayoutA1128161281128_TVLayoutB1256162561256_TVLayoutC11282561281128_CopyAtom_ThrI_0_param_3;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r47, %tid.y;
	mov.u32 	%r48, %tid.z;
	mov.u32 	%r49, %ntid.x;
	mov.u32 	%r50, %ntid.y;
	mad.lo.s32 	%r51, %r50, %r48, %r47;
	mad.lo.s32 	%r52, %r51, %r49, %r1;
	shr.u32 	%r53, %r52, 5;
	shfl.sync.idx.b32	%r2, %r53, 0, 31, -1;
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r54, __dynamic_shmem__0;
	add.s32 	%r55, %r54, 215;
	and.b32  	%r4, %r55, -896;
	setp.ne.s32 	%p13, %r2, 0;
	@%p13 bra 	$L__BB0_2;
	add.s32 	%r57, %r54, 80;
	mov.b32 	%r58, 512;
	tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r57], %r58;
	cvta.param.u64 	%rd11, %rd7;
	// begin inline asm
	prefetch.tensormap [%rd11];
	// end inline asm
	cvta.param.u64 	%rd12, %rd10;
	// begin inline asm
	prefetch.tensormap [%rd12];
	// end inline asm
	mov.b32 	%r59, 1;
	mbarrier.init.shared.b64 [%r54], %r59;
	add.s32 	%r60, %r54, 8;
	mbarrier.init.shared.b64 [%r60], %r59;
	add.s32 	%r61, %r54, 16;
	mbarrier.init.shared.b64 [%r61], %r59;
	add.s32 	%r62, %r54, 24;
	mbarrier.init.shared.b64 [%r62], %r59;
	add.s32 	%r63, %r54, 32;
	mbarrier.init.shared.b64 [%r63], %r59;
	add.s32 	%r64, %r54, 40;
	mbarrier.init.shared.b64 [%r64], %r59;
	add.s32 	%r65, %r54, 48;
	mbarrier.init.shared.b64 [%r65], %r59;
	add.s32 	%r66, %r54, 56;
	mbarrier.init.shared.b64 [%r66], %r59;
$L__BB0_2:
	setp.ne.s32 	%p14, %r2, 0;
	// begin inline asm
	fence.mbarrier_init.release.cluster;
	// end inline asm
	bar.sync 	0;
	@%p14 bra 	$L__BB0_4;
	add.s32 	%r68, %r54, 64;
	mov.b32 	%r69, 1;
	mbarrier.init.shared.b64 [%r68], %r69;
	add.s32 	%r70, %r54, 72;
	mov.b32 	%r71, 128;
	mbarrier.init.shared.b64 [%r70], %r71;
$L__BB0_4:
	mov.u32 	%r72, %ctaid.x;
	setp.ne.s32 	%p15, %r2, 0;
	// begin inline asm
	fence.mbarrier_init.release.cluster;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r73, %r44, -1;
	shr.s32 	%r74, %r73, 31;
	shr.u32 	%r75, %r74, 26;
	add.s32 	%r76, %r73, %r75;
	shr.s32 	%r77, %r76, 6;
	add.s32 	%r78, %r77, 1;
	neg.s32 	%r79, %r44;
	shr.s32 	%r80, %r79, 31;
	shr.u32 	%r81, %r80, 26;
	sub.s32 	%r82, %r81, %r44;
	shr.s32 	%r83, %r82, 6;
	neg.s32 	%r84, %r83;
	setp.gt.s32 	%p16, %r44, 0;
	selp.b32 	%r5, %r78, %r84, %p16;
	shl.b32 	%r6, %r72, 7;
	cvt.u64.u32 	%rd3, %r72;
	bar.sync 1, 128;
	ld.shared.u32 	%r7, [__dynamic_shmem__0+80];
	shl.b32 	%r8, %r1, 16;
	and.b32  	%r9, %r1, 31;
	and.b32  	%r10, %r1, 96;
	@%p15 bra 	$L__BB0_27;
	add.s32 	%r85, %r54, 72;
	// begin inline asm
	{
	.reg .pred       P1; 
	LAB_WAIT: 
	mbarrier.try_wait.parity.shared.b64 P1, [%r85], 1, 10000000; 
	@P1 bra.uni DONE; 
	bra.uni     LAB_WAIT; 
	DONE: 
	}
	// end inline asm
	setp.lt.s32 	%p17, %r5, 1;
	@%p17 bra 	$L__BB0_24;
	shr.u32 	%r91, %r55, 4;
	and.b32  	%r92, %r91, 16328;
	cvt.u64.u32 	%rd13, %r92;
	or.b64  	%rd14, %rd13, 4611756662049538048;
	mov.b64 	{%r11, %r12}, %rd14;
	add.s32 	%r93, %r4, 65536;
	shr.u32 	%r94, %r93, 4;
	and.b32  	%r95, %r94, 16328;
	cvt.u64.u32 	%rd15, %r95;
	or.b64  	%rd16, %rd15, 4611756662049538048;
	mov.b64 	{%r13, %r14}, %rd16;
	neg.s32 	%r212, %r5;
	mov.b32 	%r215, 1;
	mov.b32 	%r211, 0;
	cvta.param.u64 	%rd18, %rd7;
	cvta.param.u64 	%rd20, %rd10;
	mov.u32 	%r213, %r211;
	mov.u32 	%r214, %r211;
	mov.u32 	%r216, %r211;
$L__BB0_7:
	shl.b32 	%r98, %r216, 3;
	add.s32 	%r100, %r54, %r98;
	add.s32 	%r22, %r100, 32;
	// begin inline asm
	{
	.reg .pred       P1; 
	LAB_WAIT: 
	mbarrier.try_wait.parity.shared.b64 P1, [%r22], %r215, 10000000; 
	@P1 bra.uni DONE; 
	bra.uni     LAB_WAIT; 
	DONE: 
	}
	// end inline asm
	elect.sync 	%r101|%p18, -1;
	not.pred 	%p19, %p18;
	@%p19 bra 	$L__BB0_9;
	add.s32 	%r102, %r22, -32;
	mov.b32 	%r103, 49152;
	mbarrier.arrive.expect_tx.release.cta.shared::cta.b64 _, [%r102], %r103;
$L__BB0_9:
	shl.b32 	%r104, %r216, 14;
	add.s32 	%r23, %r4, %r104;
	add.s32 	%r24, %r22, -32;
	elect.sync 	%r105|%p20, -1;
	not.pred 	%p21, %p20;
	@%p21 bra 	$L__BB0_11;
	mov.u64 	%rd19, 0;
	cp.async.bulk.tensor.2d.shared::cluster.global.tile.mbarrier::complete_tx::bytes.L2::cache_hint [%r23], [%rd18, {%r211, %r6}], [%r24], %rd19;
$L__BB0_11:
	elect.sync 	%r106|%p22, -1;
	not.pred 	%p23, %p22;
	@%p23 bra 	$L__BB0_13;
	shl.b32 	%r107, %r216, 15;
	add.s32 	%r108, %r4, %r107;
	add.s32 	%r109, %r108, 65536;
	shl.b32 	%r110, %r3, 8;
	mov.u64 	%rd21, 0;
	cp.async.bulk.tensor.2d.shared::cluster.global.tile.mbarrier::complete_tx::bytes.L2::cache_hint [%r109], [%rd20, {%r211, %r110}], [%r24], %rd21;
$L__BB0_13:
	shl.b32 	%r113, %r214, 3;
	add.s32 	%r111, %r54, %r113;
	// begin inline asm
	{
	.reg .pred       P1; 
	LAB_WAIT: 
	mbarrier.try_wait.parity.shared.b64 P1, [%r111], %r213, 10000000; 
	@P1 bra.uni DONE; 
	bra.uni     LAB_WAIT; 
	DONE: 
	}
	// end inline asm
	add.s32 	%r26, %r214, 1;
	shl.b32 	%r115, %r214, 10;
	add.s32 	%r27, %r115, %r11;
	shl.b32 	%r116, %r214, 11;
	add.s32 	%r28, %r116, %r13;
	selp.b32 	%r117, 16384, 0, %p12;
	selp.b32 	%r118, 138420240, 138412048, %p11;
	or.b32  	%r29, %r118, %r117;
	elect.sync 	%r119|%p24, -1;
	not.pred 	%p25, %p24;
	@%p25 bra 	$L__BB0_15;
	mov.b64 	%rd22, {%r28, %r14};
	mov.b64 	%rd23, {%r27, %r12};
	mov.b32 	%r120, 0;
	tcgen05.mma.cta_group::1.kind::f16 [%r7], %rd23, %rd22, %r29, {%r120, %r120, %r120, %r120}, %p44;
$L__BB0_15:
	elect.sync 	%r121|%p26, -1;
	not.pred 	%p27, %p26;
	@%p27 bra 	$L__BB0_17;
	add.s32 	%r122, %r28, 2;
	mov.b64 	%rd24, {%r122, %r14};
	add.s32 	%r123, %r27, 2;
	mov.b64 	%rd25, {%r123, %r12};
	mov.pred 	%p28, -1;
	mov.b32 	%r124, 0;
	tcgen05.mma.cta_group::1.kind::f16 [%r7], %rd25, %rd24, %r29, {%r124, %r124, %r124, %r124}, %p28;
$L__BB0_17:
	elect.sync 	%r125|%p29, -1;
	not.pred 	%p30, %p29;
	@%p30 bra 	$L__BB0_19;
	add.s32 	%r126, %r28, 4;
	mov.b64 	%rd26, {%r126, %r14};
	add.s32 	%r127, %r27, 4;
	mov.b64 	%rd27, {%r127, %r12};
	mov.pred 	%p31, -1;
	mov.b32 	%r128, 0;
	tcgen05.mma.cta_group::1.kind::f16 [%r7], %rd27, %rd26, %r29, {%r128, %r128, %r128, %r128}, %p31;
$L__BB0_19:
	add.s32 	%r30, %r27, 6;
	add.s32 	%r31, %r28, 6;
	elect.sync 	%r129|%p32, -1;
	not.pred 	%p33, %p32;
	@%p33 bra 	$L__BB0_21;
	mov.b64 	%rd28, {%r31, %r14};
	mov.b64 	%rd29, {%r30, %r12};
	mov.pred 	%p34, -1;
	mov.b32 	%r130, 0;
	tcgen05.mma.cta_group::1.kind::f16 [%r7], %rd29, %rd28, %r29, {%r130, %r130, %r130, %r130}, %p34;
$L__BB0_21:
	elect.sync 	%r131|%p35, -1;
	not.pred 	%p36, %p35;
	@%p36 bra 	$L__BB0_23;
	add.s32 	%r132, %r111, 32;
	tcgen05.commit.cta_group::1.mbarrier::arrive::one.shared::cluster.b64 [%r132];
$L__BB0_23:
	setp.eq.s32 	%p37, %r26, 4;
	add.s32 	%r133, %r216, 1;
	setp.eq.s32 	%p38, %r133, 4;
	add.s32 	%r212, %r212, 1;
	setp.ne.s32 	%p39, %r212, 0;
	add.s32 	%r211, %r211, 64;
	selp.u32 	%r134, 1, 0, %p38;
	xor.b32  	%r215, %r215, %r134;
	selp.b32 	%r216, 0, %r133, %p38;
	selp.u32 	%r135, 1, 0, %p37;
	xor.b32  	%r213, %r213, %r135;
	selp.b32 	%r214, 0, %r26, %p37;
	mov.pred 	%p44, -1;
	@%p39 bra 	$L__BB0_7;
$L__BB0_24:
	elect.sync 	%r136|%p40, -1;
	not.pred 	%p41, %p40;
	@%p41 bra 	$L__BB0_26;
	add.s32 	%r138, %r54, 64;
	tcgen05.commit.cta_group::1.mbarrier::arrive::one.shared::cluster.b64 [%r138];
$L__BB0_26:
	tcgen05.relinquish_alloc_permit.cta_group::1.sync.aligned;
$L__BB0_27:
	add.s32 	%r139, %r54, 64;
	// begin inline asm
	{
	.reg .pred       P1; 
	LAB_WAIT: 
	mbarrier.try_wait.parity.shared.b64 P1, [%r139], 0, 10000000; 
	@P1 bra.uni DONE; 
	bra.uni     LAB_WAIT; 
	DONE: 
	}
	// end inline asm
	cvt.u64.u32 	%rd30, %r9;
	shl.b64 	%rd31, %rd3, 7;
	or.b64  	%rd32, %rd31, %rd30;
	cvt.u64.u32 	%rd33, %r10;
	add.s64 	%rd34, %rd32, %rd33;
	and.b32  	%r142, %r8, 6291456;
	add.s32 	%r217, %r7, %r142;
	mul.lo.s64 	%rd35, %rd9, %rd34;
	add.s64 	%rd36, %rd35, %rd35;
	mul.wide.u32 	%rd37, %r3, 512;
	add.s64 	%rd38, %rd36, %rd37;
	add.s64 	%rd39, %rd38, %rd8;
	add.s64 	%rd40, %rd39, 64;
	mov.b32 	%r218, 0;
$L__BB0_28:
	tcgen05.ld.sync.aligned.32x32b.x64.b32 {%r143, %r144, %r145, %r146, %r147, %r148, %r149, %r150, %r151, %r152, %r153, %r154, %r155, %r156, %r157, %r158, %r159, %r160, %r161, %r162, %r163, %r164, %r165, %r166, %r167, %r168, %r169, %r170, %r171, %r172, %r173, %r174, %r175, %r176, %r177, %r178, %r179, %r180, %r181, %r182, %r183, %r184, %r185, %r186, %r187, %r188, %r189, %r190, %r191, %r192, %r193, %r194, %r195, %r196, %r197, %r198, %r199, %r200, %r201, %r202, %r203, %r204, %r205, %r206}, [%r217];
	mov.b32 	%f1, %r143;
	mov.b32 	%f2, %r144;
	mov.b32 	%f3, %r145;
	mov.b32 	%f4, %r146;
	mov.b32 	%f5, %r147;
	mov.b32 	%f6, %r148;
	mov.b32 	%f7, %r149;
	mov.b32 	%f8, %r150;
	mov.b32 	%f9, %r151;
	mov.b32 	%f10, %r152;
	mov.b32 	%f11, %r153;
	mov.b32 	%f12, %r154;
	mov.b32 	%f13, %r155;
	mov.b32 	%f14, %r156;
	mov.b32 	%f15, %r157;
	mov.b32 	%f16, %r158;
	mov.b32 	%f17, %r159;
	mov.b32 	%f18, %r160;
	mov.b32 	%f19, %r161;
	mov.b32 	%f20, %r162;
	mov.b32 	%f21, %r163;
	mov.b32 	%f22, %r164;
	mov.b32 	%f23, %r165;
	mov.b32 	%f24, %r166;
	mov.b32 	%f25, %r167;
	mov.b32 	%f26, %r168;
	mov.b32 	%f27, %r169;
	mov.b32 	%f28, %r170;
	mov.b32 	%f29, %r171;
	mov.b32 	%f30, %r172;
	mov.b32 	%f31, %r173;
	mov.b32 	%f32, %r174;
	mov.b32 	%f33, %r175;
	mov.b32 	%f34, %r176;
	mov.b32 	%f35, %r177;
	mov.b32 	%f36, %r178;
	mov.b32 	%f37, %r179;
	mov.b32 	%f38, %r180;
	mov.b32 	%f39, %r181;
	mov.b32 	%f40, %r182;
	mov.b32 	%f41, %r183;
	mov.b32 	%f42, %r184;
	mov.b32 	%f43, %r185;
	mov.b32 	%f44, %r186;
	mov.b32 	%f45, %r187;
	mov.b32 	%f46, %r188;
	mov.b32 	%f47, %r189;
	mov.b32 	%f48, %r190;
	mov.b32 	%f49, %r191;
	mov.b32 	%f50, %r192;
	mov.b32 	%f51, %r193;
	mov.b32 	%f52, %r194;
	mov.b32 	%f53, %r195;
	mov.b32 	%f54, %r196;
	mov.b32 	%f55, %r197;
	mov.b32 	%f56, %r198;
	mov.b32 	%f57, %r199;
	mov.b32 	%f58, %r200;
	mov.b32 	%f59, %r201;
	mov.b32 	%f60, %r202;
	mov.b32 	%f61, %r203;
	mov.b32 	%f62, %r204;
	mov.b32 	%f63, %r205;
	mov.b32 	%f64, %r206;
	cvt.rn.f16.f32 	%rs7, %f64;
	cvt.rn.f16.f32 	%rs8, %f63;
	cvt.rn.f16.f32 	%rs9, %f62;
	cvt.rn.f16.f32 	%rs10, %f61;
	cvt.rn.f16.f32 	%rs11, %f60;
	cvt.rn.f16.f32 	%rs12, %f59;
	cvt.rn.f16.f32 	%rs13, %f58;
	cvt.rn.f16.f32 	%rs14, %f57;
	cvt.rn.f16.f32 	%rs15, %f56;
	cvt.rn.f16.f32 	%rs16, %f55;
	cvt.rn.f16.f32 	%rs17, %f54;
	cvt.rn.f16.f32 	%rs18, %f53;
	cvt.rn.f16.f32 	%rs19, %f52;
	cvt.rn.f16.f32 	%rs20, %f51;
	cvt.rn.f16.f32 	%rs21, %f50;
	cvt.rn.f16.f32 	%rs22, %f49;
	cvt.rn.f16.f32 	%rs23, %f48;
	cvt.rn.f16.f32 	%rs24, %f47;
	cvt.rn.f16.f32 	%rs25, %f46;
	cvt.rn.f16.f32 	%rs26, %f45;
	cvt.rn.f16.f32 	%rs27, %f44;
	cvt.rn.f16.f32 	%rs28, %f43;
	cvt.rn.f16.f32 	%rs29, %f42;
	cvt.rn.f16.f32 	%rs30, %f41;
	cvt.rn.f16.f32 	%rs31, %f40;
	cvt.rn.f16.f32 	%rs32, %f39;
	cvt.rn.f16.f32 	%rs33, %f38;
	cvt.rn.f16.f32 	%rs34, %f37;
	cvt.rn.f16.f32 	%rs35, %f36;
	cvt.rn.f16.f32 	%rs36, %f35;
	cvt.rn.f16.f32 	%rs37, %f34;
	cvt.rn.f16.f32 	%rs38, %f33;
	cvt.rn.f16.f32 	%rs39, %f32;
	cvt.rn.f16.f32 	%rs40, %f31;
	cvt.rn.f16.f32 	%rs41, %f30;
	cvt.rn.f16.f32 	%rs42, %f29;
	cvt.rn.f16.f32 	%rs43, %f28;
	cvt.rn.f16.f32 	%rs44, %f27;
	cvt.rn.f16.f32 	%rs45, %f26;
	cvt.rn.f16.f32 	%rs46, %f25;
	cvt.rn.f16.f32 	%rs47, %f24;
	cvt.rn.f16.f32 	%rs48, %f23;
	cvt.rn.f16.f32 	%rs49, %f22;
	cvt.rn.f16.f32 	%rs50, %f21;
	cvt.rn.f16.f32 	%rs51, %f20;
	cvt.rn.f16.f32 	%rs52, %f19;
	cvt.rn.f16.f32 	%rs53, %f18;
	cvt.rn.f16.f32 	%rs54, %f17;
	cvt.rn.f16.f32 	%rs55, %f16;
	cvt.rn.f16.f32 	%rs56, %f15;
	cvt.rn.f16.f32 	%rs57, %f14;
	cvt.rn.f16.f32 	%rs58, %f13;
	cvt.rn.f16.f32 	%rs59, %f12;
	cvt.rn.f16.f32 	%rs60, %f11;
	cvt.rn.f16.f32 	%rs61, %f10;
	cvt.rn.f16.f32 	%rs62, %f9;
	cvt.rn.f16.f32 	%rs63, %f8;
	cvt.rn.f16.f32 	%rs64, %f7;
	cvt.rn.f16.f32 	%rs65, %f6;
	cvt.rn.f16.f32 	%rs66, %f5;
	cvt.rn.f16.f32 	%rs67, %f4;
	cvt.rn.f16.f32 	%rs68, %f3;
	cvt.rn.f16.f32 	%rs69, %f2;
	cvt.rn.f16.f32 	%rs70, %f1;
	st.global.b16 	[%rd40+-64], %rs70;
	st.global.b16 	[%rd40+-62], %rs69;
	st.global.b16 	[%rd40+-60], %rs68;
	st.global.b16 	[%rd40+-58], %rs67;
	st.global.b16 	[%rd40+-56], %rs66;
	st.global.b16 	[%rd40+-54], %rs65;
	st.global.b16 	[%rd40+-52], %rs64;
	st.global.b16 	[%rd40+-50], %rs63;
	st.global.b16 	[%rd40+-48], %rs62;
	st.global.b16 	[%rd40+-46], %rs61;
	st.global.b16 	[%rd40+-44], %rs60;
	st.global.b16 	[%rd40+-42], %rs59;
	st.global.b16 	[%rd40+-40], %rs58;
	st.global.b16 	[%rd40+-38], %rs57;
	st.global.b16 	[%rd40+-36], %rs56;
	st.global.b16 	[%rd40+-34], %rs55;
	st.global.b16 	[%rd40+-32], %rs54;
	st.global.b16 	[%rd40+-30], %rs53;
	st.global.b16 	[%rd40+-28], %rs52;
	st.global.b16 	[%rd40+-26], %rs51;
	st.global.b16 	[%rd40+-24], %rs50;
	st.global.b16 	[%rd40+-22], %rs49;
	st.global.b16 	[%rd40+-20], %rs48;
	st.global.b16 	[%rd40+-18], %rs47;
	st.global.b16 	[%rd40+-16], %rs46;
	st.global.b16 	[%rd40+-14], %rs45;
	st.global.b16 	[%rd40+-12], %rs44;
	st.global.b16 	[%rd40+-10], %rs43;
	st.global.b16 	[%rd40+-8], %rs42;
	st.global.b16 	[%rd40+-6], %rs41;
	st.global.b16 	[%rd40+-4], %rs40;
	st.global.b16 	[%rd40+-2], %rs39;
	st.global.b16 	[%rd40], %rs38;
	st.global.b16 	[%rd40+2], %rs37;
	st.global.b16 	[%rd40+4], %rs36;
	st.global.b16 	[%rd40+6], %rs35;
	st.global.b16 	[%rd40+8], %rs34;
	st.global.b16 	[%rd40+10], %rs33;
	st.global.b16 	[%rd40+12], %rs32;
	st.global.b16 	[%rd40+14], %rs31;
	st.global.b16 	[%rd40+16], %rs30;
	st.global.b16 	[%rd40+18], %rs29;
	st.global.b16 	[%rd40+20], %rs28;
	st.global.b16 	[%rd40+22], %rs27;
	st.global.b16 	[%rd40+24], %rs26;
	st.global.b16 	[%rd40+26], %rs25;
	st.global.b16 	[%rd40+28], %rs24;
	st.global.b16 	[%rd40+30], %rs23;
	st.global.b16 	[%rd40+32], %rs22;
	st.global.b16 	[%rd40+34], %rs21;
	st.global.b16 	[%rd40+36], %rs20;
	st.global.b16 	[%rd40+38], %rs19;
	st.global.b16 	[%rd40+40], %rs18;
	st.global.b16 	[%rd40+42], %rs17;
	st.global.b16 	[%rd40+44], %rs16;
	st.global.b16 	[%rd40+46], %rs15;
	st.global.b16 	[%rd40+48], %rs14;
	st.global.b16 	[%rd40+50], %rs13;
	st.global.b16 	[%rd40+52], %rs12;
	st.global.b16 	[%rd40+54], %rs11;
	st.global.b16 	[%rd40+56], %rs10;
	st.global.b16 	[%rd40+58], %rs9;
	st.global.b16 	[%rd40+60], %rs8;
	st.global.b16 	[%rd40+62], %rs7;
	add.s32 	%r218, %r218, 1;
	add.s32 	%r217, %r217, 64;
	add.s64 	%rd40, %rd40, 128;
	setp.ne.s32 	%p42, %r218, 4;
	@%p42 bra 	$L__BB0_28;
	setp.ne.s32 	%p43, %r2, 0;
	mov.u32 	%r207, __dynamic_shmem__0;
	add.s32 	%r208, %r207, 72;
	mov.b32 	%r209, 1;
	mbarrier.arrive.release.cta.shared::cta.b64 _, [%r208], %r209;
	bar.sync 	%r209;
	@%p43 bra 	$L__BB0_31;
	mov.b32 	%r210, 512;
	tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r7, %r210;
$L__BB0_31:
	ret;

}
 